From 3ef58814e39ce3cfe9d0758e60d2d134118af593 Mon Sep 17 00:00:00 2001
From: Sridharan S N <quic_sridsn@quicinc.com>
Date: Fri, 15 Dec 2023 11:00:13 +0530
Subject: [PATCH 185/500] mtd: rawnand: qcom: add snapshot from linux-6.1

Taken the snapshot of the qcom_nandc driver from linux-6.1 as of commit
dab3dac67d6f ("drivers: mtd: qcom_nandc: Add switch layout support")

Change-Id: I4dad1f0fc758b4a696b8243b03ca44c17326ad0c
Signed-off-by: Sridharan S N <quic_sridsn@quicinc.com>
---
 drivers/mtd/nand/raw/qcom_nandc.c | 2186 ++++++++++++++++++++---------
 1 file changed, 1539 insertions(+), 647 deletions(-)

diff --git a/drivers/mtd/nand/raw/qcom_nandc.c b/drivers/mtd/nand/raw/qcom_nandc.c
index b079605c84d3..86da3abf39ca 100644
--- a/drivers/mtd/nand/raw/qcom_nandc.c
+++ b/drivers/mtd/nand/raw/qcom_nandc.c
@@ -2,19 +2,19 @@
 /*
  * Copyright (c) 2016, The Linux Foundation. All rights reserved.
  */
-#include <linux/bitops.h>
 #include <linux/clk.h>
-#include <linux/delay.h>
-#include <linux/dmaengine.h>
-#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/bitops.h>
 #include <linux/dma/qcom_adm.h>
-#include <linux/dma/qcom_bam_dma.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmaengine.h>
 #include <linux/module.h>
-#include <linux/mtd/partitions.h>
 #include <linux/mtd/rawnand.h>
+#include <linux/mtd/partitions.h>
 #include <linux/of.h>
-#include <linux/platform_device.h>
-#include <linux/slab.h>
+#include <linux/of_device.h>
+#include <linux/delay.h>
+#include <linux/dma/qcom_bam_dma.h>
 
 /* NANDc reg offsets */
 #define	NAND_FLASH_CMD			0x00
@@ -36,6 +36,17 @@
 #define	NAND_DEV_CMD1			0xa4
 #define	NAND_DEV_CMD2			0xa8
 #define	NAND_DEV_CMD_VLD		0xac
+#define	NAND_DEV_CMD7			0xb0
+#define	NAND_DEV_CMD8			0xb4
+#define	NAND_DEV_CMD9			0xb8
+#define	NAND_FLASH_SPI_CFG		0xc0
+#define	NAND_SPI_NUM_ADDR_CYCLES	0xc4
+#define	NAND_SPI_BUSY_CHECK_WAIT_CNT	0xc8
+#define	NAND_DEV_CMD3			0xd0
+#define	NAND_DEV_CMD4			0xd4
+#define	NAND_DEV_CMD5			0xd8
+#define	NAND_DEV_CMD6			0xdc
+#
 #define	SFLASHC_BURST_CFG		0xe0
 #define	NAND_ERASED_CW_DETECT_CFG	0xe8
 #define	NAND_ERASED_CW_DETECT_STATUS	0xec
@@ -52,6 +63,9 @@
 #define	NAND_READ_LOCATION_LAST_CW_1	0xf44
 #define	NAND_READ_LOCATION_LAST_CW_2	0xf48
 #define	NAND_READ_LOCATION_LAST_CW_3	0xf4c
+#define	NAND_QSPI_MSTR_CONFIG		0xf60
+#define	NAND_FLASH_FEATURES		0xf64
+
 
 /* dummy register offsets, used by write_reg_dma */
 #define	NAND_DEV_CMD1_RESTORE		0xdead
@@ -71,6 +85,8 @@
 #define	FS_MPU_ERR			BIT(8)
 #define	FS_DEVICE_STS_ERR		BIT(16)
 #define	FS_DEVICE_WP			BIT(23)
+#define FS_TIMEOUT_ERR                  BIT(6)
+#define FLASH_ERROR                     (FS_OP_ERR | FS_MPU_ERR | FS_TIMEOUT_ERR)
 
 /* NAND_BUFFER_STATUS bits */
 #define	BS_UNCORRECTABLE_BIT		BIT(8)
@@ -123,8 +139,8 @@
 /* NAND_ERASED_CW_DETECT_CFG bits */
 #define	ERASED_CW_ECC_MASK		1
 #define	AUTO_DETECT_RES			0
-#define	MASK_ECC			BIT(ERASED_CW_ECC_MASK)
-#define	RESET_ERASED_DET		BIT(AUTO_DETECT_RES)
+#define	MASK_ECC			(1 << ERASED_CW_ECC_MASK)
+#define	RESET_ERASED_DET		(1 << AUTO_DETECT_RES)
 #define	ACTIVE_ERASED_DET		(0 << AUTO_DETECT_RES)
 #define	CLR_ERASED_PAGE_DET		(RESET_ERASED_DET | MASK_ECC)
 #define	SET_ERASED_PAGE_DET		(ACTIVE_ERASED_DET | MASK_ECC)
@@ -157,9 +173,9 @@
 #define	OP_PAGE_PROGRAM_WITH_ECC	0x7
 #define	OP_PROGRAM_PAGE_SPARE		0x9
 #define	OP_BLOCK_ERASE			0xa
-#define	OP_CHECK_STATUS			0xc
 #define	OP_FETCH_ID			0xb
 #define	OP_RESET_DEVICE			0xd
+#define ACC_FEATURE                     0xe
 
 /* Default Value for NAND_DEV_CMD_VLD */
 #define NAND_DEV_CMD_VLD_VAL		(READ_START_VLD | WRITE_START_VLD | \
@@ -189,6 +205,61 @@
 #define	ECC_BCH_4BIT	BIT(2)
 #define	ECC_BCH_8BIT	BIT(3)
 
+#define LOAD_CLK_CNTR_INIT_EN   (1 << 28)
+#define CLK_CNTR_INIT_VAL_VEC   0x924
+#define FEA_STATUS_DEV_ADDR     0xc0
+#define SPI_CFG (1 << 0)
+
+/* CMD register value for qspi nand */
+#define	CMD0_VAL	0x1080D8D8
+#define	CMD1_VAL	0xF00F3000
+#define	CMD2_VAL	0xF0FF709F
+#define	CMD3_VAL	0x3F310015
+#define	CMD3_MASK	0xfff0ffff
+#define	CMD7_VAL	0x04061F0F
+#define	CMD_VLD_VAL	0xd
+#define	SPI_NUM_ADDR	0xDA4DB
+#define	WAIT_CNT	0x10
+
+/*
+ * SPI Nand flash device ID's
+ */
+#define	SPI_FLASH_MICRON_ID		0x2c
+#define	SPI_FLASH_ESMT_DEVICE_ID	0x11
+#define	SPI_FLASH_WINBOND_ID		0xef
+#define	SPI_WINBOND_DEVICE_1		0xba
+#define	SPI_FLASH_GIGA_ID		0xc8
+
+/*
+ * Serial NAND flash commands
+ */
+#define	NAND_CMD_READID_SERIAL		0x9F
+#define	NAND_CMD_ERASE_SERIAL		0xd8
+#define	NAND_CMD_SET_FEATURE_SERIAL	0x1F
+#define	NAND_CMD_GET_FEATURE_SERIAL	0x0F
+#define	SPI_FLASH_FEATURE_REG		0xB0
+
+/*
+ * Serial NAND flash status register bits
+ */
+#define	SPI_FLASH_QUAD_MODE		0x1
+#define	SPI_NAND_BUF_BIT(x)		(1 << x)
+
+/* QSPI NAND CMD reg bits value */
+#define	SPI_WP		(1 << 28)
+#define	SPI_HOLD	(1 << 27)
+#define	SPI_TRANSFER_MODE_x1	(1 << 29)
+#define	SPI_TRANSFER_MODE_x4	(3 << 29)
+#define	QPIC_SET_FEATURE	(1 << 31)
+#define QPIC_v2_0	0x2
+#define FEEDBACK_CLK_EN	(1 << 4)
+#define MAX_TRAINING_BLK	8
+#define TOTAL_NUM_PHASE	7
+#define	AUTO_STS_VAL	0x000B000B
+#define	PAGE_SCOPE_READ	(1 << 23)
+#define	MAX_STATUS_REG	12
+#define IO_MACRO_50_MHZ	50000000
+
 #define nandc_set_read_loc_first(chip, reg, cw_offset, read_size, is_last_read_loc)	\
 nandc_set_reg(chip, reg,			\
 	      ((cw_offset) << READ_LOCATION_OFFSET) |		\
@@ -212,11 +283,12 @@ nandc_set_reg(chip, reg,			\
 /* Returns the dma address for reg read buffer */
 #define reg_buf_dma_addr(chip, vaddr) \
 	((chip)->reg_read_dma + \
-	((u8 *)(vaddr) - (u8 *)(chip)->reg_read_buf))
+	((uint8_t *)(vaddr) - (uint8_t *)(chip)->reg_read_buf))
 
 #define QPIC_PER_CW_CMD_ELEMENTS	32
 #define QPIC_PER_CW_CMD_SGL		32
 #define QPIC_PER_CW_DATA_SGL		8
+#define QPIC_PER_CW_STS_SGL             8
 
 #define QPIC_NAND_COMPLETION_TIMEOUT	msecs_to_jiffies(2000)
 
@@ -236,7 +308,24 @@ nandc_set_reg(chip, reg,			\
  */
 #define NAND_ERASED_CW_SET		BIT(4)
 
-#define MAX_ADDRESS_CYCLE		5
+#define NAND_MID_WINBOND		0xEF
+
+/*
+ * An array holding the fixed pattern
+ */
+static const u32 qspi_training_block_64[] = {
+	0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F,
+	0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F,
+	0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F,
+	0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F, 0x0F0F0F0F,
+};
+
+struct nand_flash_dev qspinand_flash_ids_2k[] = {
+	{"MX35UF4GE4AD-Z4I SPI NAND 1G 1.8V",
+			{ .id = {0xc2, 0xb7} },
+		SZ_2K, SZ_256, SZ_128K, 0, 2, 128, NAND_ECC_INFO(8, SZ_512), 0},
+	{NULL}
+};
 
 /*
  * This data type corresponds to the BAM transaction which will be used for all
@@ -264,6 +353,7 @@ struct bam_transaction {
 	struct bam_cmd_element *bam_ce;
 	struct scatterlist *cmd_sgl;
 	struct scatterlist *data_sgl;
+	struct scatterlist *sts_sgl;
 	struct dma_async_tx_descriptor *last_data_desc;
 	struct dma_async_tx_descriptor *last_cmd_desc;
 	struct completion txn_done;
@@ -275,6 +365,8 @@ struct bam_transaction {
 	u32 tx_sgl_start;
 	u32 rx_sgl_pos;
 	u32 rx_sgl_start;
+	u32 sts_sgl_pos;
+	u32 sts_sgl_start;
 	bool wait_second_completion;
 };
 
@@ -336,9 +428,17 @@ struct nandc_regs {
 	__le32 read_location_last1;
 	__le32 read_location_last2;
 	__le32 read_location_last3;
+	__le32 flash_feature;
+	__le32 spi_cfg;
+	__le32 num_addr_cycle;
+	__le32 busy_wait_cnt;
+	__le32 mstr_cfg;

+
 	__le32 erased_cw_detect_cfg_clr;
 	__le32 erased_cw_detect_cfg_set;
+	__le32 auto_sts_en;
+
 };
 
 /*
@@ -371,6 +471,8 @@ struct nandc_regs {
  * @data_buffer:		our local DMA buffer for page read/writes,
  *				used when we can't use the buffer provided
  *				by upper layers directly
+ * @boot_layout:		flag to tell whether current layout is boot
+ *				layout
  * @reg_read_buf:		local buffer for reading back registers via DMA
  *
  * @base_phys:			physical base address of controller registers
@@ -385,9 +487,6 @@ struct nandc_regs {
  * @reg_read_pos:		marker for data read in reg_read_buf
  *
  * @cmd1/vld:			some fixed controller register values
- *
- * @exec_opwrite:		flag to select correct number of code word
- *				while reading status
  */
 struct qcom_nand_controller {
 	struct device *dev;
@@ -396,6 +495,7 @@ struct qcom_nand_controller {
 
 	struct clk *core_clk;
 	struct clk *aon_clk;
+	struct clk *iomacro_clk;
 
 	struct nandc_regs *regs;
 	struct bam_transaction *bam_txn;
@@ -411,6 +511,7 @@ struct qcom_nand_controller {
 			struct dma_chan *tx_chan;
 			struct dma_chan *rx_chan;
 			struct dma_chan *cmd_chan;
+			struct dma_chan *sts_chan;
 		};
 
 		/* will be used only by EBI2 for ADM DMA */
@@ -424,6 +525,7 @@ struct qcom_nand_controller {
 	struct list_head desc_list;
 
 	u8		*data_buffer;
+	bool		boot_layout;
 	__le32		*reg_read_buf;
 
 	phys_addr_t base_phys;
@@ -438,7 +540,8 @@ struct qcom_nand_controller {
 	int reg_read_pos;
 
 	u32 cmd1, vld;
-	bool exec_opwrite;
+	__le32 *status_buf;
+	int sts_buf_size;
 };
 
 /*
@@ -455,29 +558,6 @@ struct qcom_nand_boot_partition {
 };
 
 /*
- * Qcom op for each exec_op transfer
- *
- * @data_instr:			data instruction pointer
- * @data_instr_idx:		data instruction index
- * @rdy_timeout_ms:		wait ready timeout in ms
- * @rdy_delay_ns:		Additional delay in ns
- * @addr1_reg:			Address1 register value
- * @addr2_reg:			Address2 register value
- * @cmd_reg:			CMD register value
- * @flag:			flag for misc instruction
- */
-struct qcom_op {
-	const struct nand_op_instr *data_instr;
-	unsigned int data_instr_idx;
-	unsigned int rdy_timeout_ms;
-	unsigned int rdy_delay_ns;
-	u32 addr1_reg;
-	u32 addr2_reg;
-	u32 cmd_reg;
-	u8 flag;
-};
-
-/*
  * NAND chip structure
  *
  * @boot_partitions:		array of boot partitions where offset and size of the
@@ -542,6 +622,8 @@ struct qcom_nand_host {
 	bool codeword_fixup;
 	bool use_ecc;
 	bool bch_enabled;
+	bool quad_mode;
+	bool check_qe_bit;
 };
 
 /*
@@ -553,14 +635,20 @@ struct qcom_nand_host {
  * @is_qpic - whether NAND CTRL is part of qpic IP
  * @qpic_v2 - flag to indicate QPIC IP version 2
  * @use_codeword_fixup - whether NAND has different layout for boot partitions
+ * @switch_layout - flag to enable or disable switching of nand page size
  */
 struct qcom_nandc_props {
 	u32 ecc_modes;
 	u32 dev_cmd_reg_start;
 	bool is_bam;
 	bool is_qpic;
+	bool is_serial_nand;
 	bool qpic_v2;
 	bool use_codeword_fixup;
+	bool is_serial_training;
+	bool quad_mode;
+	bool page_scope;
+	bool switch_layout;
 };
 
 /* Frees the BAM transaction memory */
@@ -585,6 +673,8 @@ alloc_bam_transaction(struct qcom_nand_controller *nandc)
 		((sizeof(*bam_txn->bam_ce) * QPIC_PER_CW_CMD_ELEMENTS) +
 		(sizeof(*bam_txn->cmd_sgl) * QPIC_PER_CW_CMD_SGL) +
 		(sizeof(*bam_txn->data_sgl) * QPIC_PER_CW_DATA_SGL));
+	if (nandc->props->qpic_v2)
+		bam_txn_size += sizeof(*bam_txn->sts_sgl) * QPIC_PER_CW_STS_SGL * num_cw;
 
 	bam_txn_buf = devm_kzalloc(nandc->dev, bam_txn_size, GFP_KERNEL);
 	if (!bam_txn_buf)
@@ -603,6 +693,12 @@ alloc_bam_transaction(struct qcom_nand_controller *nandc)
 
 	bam_txn->data_sgl = bam_txn_buf;
 
+	if (nandc->props->qpic_v2) {
+		bam_txn_buf +=
+			sizeof(*bam_txn->data_sgl) * QPIC_PER_CW_DATA_SGL * num_cw;
+		bam_txn->sts_sgl = bam_txn_buf;
+	}
+
 	init_completion(&bam_txn->txn_done);
 
 	return bam_txn;
@@ -632,6 +728,13 @@ static void clear_bam_transaction(struct qcom_nand_controller *nandc)
 	sg_init_table(bam_txn->data_sgl, nandc->max_cwperpage *
 		      QPIC_PER_CW_DATA_SGL);
 
+	if (nandc->props->qpic_v2) {
+		bam_txn->sts_sgl_pos = 0;
+		bam_txn->sts_sgl_start = 0;
+		sg_init_table(bam_txn->sts_sgl, nandc->max_cwperpage *
+			      QPIC_PER_CW_STS_SGL);
+	}
+
 	reinit_completion(&bam_txn->txn_done);
 }
 
@@ -715,6 +818,8 @@ static __le32 *offset_to_nandc_reg(struct nandc_regs *regs, int offset)
 		return &regs->cfg1;
 	case NAND_DEV0_ECC_CFG:
 		return &regs->ecc_bch_cfg;
+	case NAND_AUTO_STATUS_EN:
+		return &regs->auto_sts_en;
 	case NAND_READ_STATUS:
 		return &regs->clrreadstatus;
 	case NAND_DEV_CMD1:
@@ -743,6 +848,16 @@ static __le32 *offset_to_nandc_reg(struct nandc_regs *regs, int offset)
 		return &regs->read_location_last2;
 	case NAND_READ_LOCATION_LAST_CW_3:
 		return &regs->read_location_last3;
+	case NAND_FLASH_SPI_CFG:
+		return &regs->spi_cfg;
+	case NAND_SPI_NUM_ADDR_CYCLES:
+		return &regs->num_addr_cycle;
+	case NAND_SPI_BUSY_CHECK_WAIT_CNT:
+		return &regs->busy_wait_cnt;
+	case NAND_QSPI_MSTR_CONFIG:
+		return &regs->mstr_cfg;
+	case NAND_FLASH_FEATURES:
+		return &regs->flash_feature;
 	default:
 		return NULL;
 	}
@@ -814,13 +929,26 @@ static void update_rw_regs(struct qcom_nand_host *host, int num_cw, bool read, i
 	u32 cmd, cfg0, cfg1, ecc_bch_cfg;
 	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
 
-	if (read) {
-		if (host->use_ecc)
-			cmd = OP_PAGE_READ_WITH_ECC | PAGE_ACC | LAST_PAGE;
+	cmd = (PAGE_ACC | LAST_PAGE);
+
+	if (nandc->props->is_serial_nand) {
+		if (nandc->props->quad_mode && host->quad_mode)
+			cmd |= SPI_TRANSFER_MODE_x4;
 		else
-			cmd = OP_PAGE_READ | PAGE_ACC | LAST_PAGE;
+			cmd |= SPI_TRANSFER_MODE_x1;
+		cmd |= (SPI_WP | SPI_HOLD);
+	}
+
+	if (read) {
+		if (host->use_ecc) {
+			cmd |= OP_PAGE_READ_WITH_ECC;
+			if (nandc->props->qpic_v2 && nandc->props->page_scope)
+				cmd |= PAGE_SCOPE_READ;
+		} else {
+			cmd |= OP_PAGE_READ;
+		}
 	} else {
-		cmd = OP_PROGRAM_PAGE | PAGE_ACC | LAST_PAGE;
+		cmd |= OP_PROGRAM_PAGE;
 	}
 
 	if (host->use_ecc) {
@@ -841,6 +969,8 @@ static void update_rw_regs(struct qcom_nand_host *host, int num_cw, bool read, i
 	nandc_set_reg(chip, NAND_DEV0_CFG0, cfg0);
 	nandc_set_reg(chip, NAND_DEV0_CFG1, cfg1);
 	nandc_set_reg(chip, NAND_DEV0_ECC_CFG, ecc_bch_cfg);
+	if (nandc->props->qpic_v2 && nandc->props->page_scope)
+		nandc_set_reg(chip, NAND_AUTO_STATUS_EN, AUTO_STS_VAL);
 	if (!nandc->props->qpic_v2)
 		nandc_set_reg(chip, NAND_EBI2_ECC_BUF_CFG, host->ecc_buf_cfg);
 	nandc_set_reg(chip, NAND_FLASH_STATUS, host->clrflashstatus);
@@ -885,6 +1015,12 @@ static int prepare_bam_async_desc(struct qcom_nand_controller *nandc,
 		bam_txn->tx_sgl_start = bam_txn->tx_sgl_pos;
 		dir_eng = DMA_MEM_TO_DEV;
 		desc->dir = DMA_TO_DEVICE;
+	} else if (nandc->props->qpic_v2 && chan == nandc->sts_chan) {
+		sgl = &bam_txn->sts_sgl[bam_txn->sts_sgl_start];
+		sgl_cnt = bam_txn->sts_sgl_pos - bam_txn->sts_sgl_start;
+		bam_txn->sts_sgl_start = bam_txn->sts_sgl_pos;
+		dir_eng = DMA_DEV_TO_MEM;
+		desc->dir = DMA_FROM_DEVICE;
 	} else {
 		sgl = &bam_txn->data_sgl[bam_txn->rx_sgl_start];
 		sgl_cnt = bam_txn->rx_sgl_pos - bam_txn->rx_sgl_start;
@@ -1159,6 +1295,10 @@ static int write_reg_dma(struct qcom_nand_controller *nandc, int first,
 	if (first == NAND_EXEC_CMD)
 		flags |= NAND_BAM_NWD;
 
+	if (first == NAND_FLASH_SPI_CFG || first == NAND_SPI_NUM_ADDR_CYCLES
+			|| first == NAND_SPI_BUSY_CHECK_WAIT_CNT)
+		first = dev_cmd_reg_addr(nandc, first);
+
 	if (first == NAND_DEV_CMD1_RESTORE || first == NAND_DEV_CMD1)
 		first = dev_cmd_reg_addr(nandc, NAND_DEV_CMD1);
 
@@ -1177,6 +1317,27 @@ static int write_reg_dma(struct qcom_nand_controller *nandc, int first,
 }
 
 /*
+ * read_status_data_dma: prepares a DMA descriptor to transfer status from the
+ * 			 controller's status registers to buffer 'vaddr'
+ *
+ * @reg_off:            offset within the controller's data buffer
+ * @vaddr:              virtual address of the buffer we want to write to
+ * @size:               DMA transaction size in bytes
+ * @flags:              flags to control DMA descriptor preparation
+ */
+static int read_status_data_dma(struct qcom_nand_controller *nandc, int reg_off,
+		const u8 *vaddr, int size, unsigned int flags)
+{
+	struct bam_transaction *bam_txn = nandc->bam_txn;
+
+	sg_set_buf(&bam_txn->sts_sgl[bam_txn->sts_sgl_pos],
+			vaddr, size);
+	bam_txn->sts_sgl_pos++;
+
+	return 0;
+}
+
+/*
  * read_data_dma:	prepares a DMA descriptor to transfer data from the
  *			controller's internal buffer to the buffer 'vaddr'
  *
@@ -1248,13 +1409,20 @@ config_nand_cw_read(struct nand_chip *chip, bool use_ecc, int cw)
 		write_reg_dma(nandc, reg, 4, NAND_BAM_NEXT_SGL);
 
 	write_reg_dma(nandc, NAND_FLASH_CMD, 1, NAND_BAM_NEXT_SGL);
-	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
 
 	if (use_ecc) {
-		read_reg_dma(nandc, NAND_FLASH_STATUS, 2, 0);
-		read_reg_dma(nandc, NAND_ERASED_CW_DETECT_STATUS, 1,
-			     NAND_BAM_NEXT_SGL);
+		if (nandc->props->qpic_v2 && nandc->props->page_scope) {
+			write_reg_dma(nandc, NAND_AUTO_STATUS_EN, 1, NAND_BAM_NEXT_SGL);
+			if (qcom_nandc_is_last_cw(ecc, cw))
+				write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+		} else {
+			write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+			read_reg_dma(nandc, NAND_FLASH_STATUS, 2, 0);
+			read_reg_dma(nandc, NAND_ERASED_CW_DETECT_STATUS, 1,
+			       NAND_BAM_NEXT_SGL);
+		}
 	} else {
+		write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
 		read_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);
 	}
 }
@@ -1303,33 +1471,218 @@ static void config_nand_cw_write(struct nand_chip *chip)
 	write_reg_dma(nandc, NAND_READ_STATUS, 1, NAND_BAM_NEXT_SGL);
 }
 
+/*
+ * the following functions are used within chip->legacy.cmdfunc() to
+ * perform different NAND_CMD_* commands
+ */
+
+/* sets up descriptors for NAND_CMD_PARAM */
+static int nandc_param(struct qcom_nand_host *host)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+
+	/*
+	 * NAND_CMD_PARAM is called before we know much about the FLASH chip
+	 * in use. we configure the controller to perform a raw read of 512
+	 * bytes to read onfi params
+	 */
+	if (nandc->props->qpic_v2)
+		nandc_set_reg(chip, NAND_FLASH_CMD, OP_PAGE_READ_ONFI_READ |
+			      PAGE_ACC | LAST_PAGE);
+	else
+		nandc_set_reg(chip, NAND_FLASH_CMD, OP_PAGE_READ |
+			      PAGE_ACC | LAST_PAGE);
+
+	nandc_set_reg(chip, NAND_ADDR0, 0);
+	nandc_set_reg(chip, NAND_ADDR1, 0);
+	nandc_set_reg(chip, NAND_DEV0_CFG0, 0 << CW_PER_PAGE
+					| 512 << UD_SIZE_BYTES
+					| 5 << NUM_ADDR_CYCLES
+					| 0 << SPARE_SIZE_BYTES);
+	nandc_set_reg(chip, NAND_DEV0_CFG1, 7 << NAND_RECOVERY_CYCLES
+					| 0 << CS_ACTIVE_BSY
+					| 17 << BAD_BLOCK_BYTE_NUM
+					| 1 << BAD_BLOCK_IN_SPARE_AREA
+					| 2 << WR_RD_BSY_GAP
+					| 0 << WIDE_FLASH
+					| 1 << DEV0_CFG1_ECC_DISABLE);
+	if (!nandc->props->qpic_v2)
+		nandc_set_reg(chip, NAND_EBI2_ECC_BUF_CFG, 1 << ECC_CFG_ECC_DISABLE);
+
+	/* configure CMD1 and VLD for ONFI param probing in QPIC v1 */
+	if (!nandc->props->qpic_v2) {
+		nandc_set_reg(chip, NAND_DEV_CMD_VLD,
+			      (nandc->vld & ~READ_START_VLD));
+		nandc_set_reg(chip, NAND_DEV_CMD1,
+			      (nandc->cmd1 & ~(0xFF << READ_ADDR))
+			      | NAND_CMD_PARAM << READ_ADDR);
+	}
+
+	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
+
+	if (!nandc->props->qpic_v2) {
+		nandc_set_reg(chip, NAND_DEV_CMD1_RESTORE, nandc->cmd1);
+		nandc_set_reg(chip, NAND_DEV_CMD_VLD_RESTORE, nandc->vld);
+	}
+
+	nandc_set_read_loc(chip, 0, 0, 0, 512, 1);
+
+	if (!nandc->props->qpic_v2) {
+		write_reg_dma(nandc, NAND_DEV_CMD_VLD, 1, 0);
+		write_reg_dma(nandc, NAND_DEV_CMD1, 1, NAND_BAM_NEXT_SGL);
+	}
+
+	nandc->buf_count = 512;
+	memset(nandc->data_buffer, 0xff, nandc->buf_count);
+
+	config_nand_single_cw_page_read(chip, false, 0);
+
+	read_data_dma(nandc, FLASH_BUF_ACC, nandc->data_buffer,
+		      nandc->buf_count, 0);
+
+	/* restore CMD1 and VLD regs */
+	if (!nandc->props->qpic_v2) {
+		write_reg_dma(nandc, NAND_DEV_CMD1_RESTORE, 1, 0);
+		write_reg_dma(nandc, NAND_DEV_CMD_VLD_RESTORE, 1, NAND_BAM_NEXT_SGL);
+	}
+
+	return 0;
+}
+
+/* sets up descriptors for NAND_CMD_ERASE1 */
+static int erase_block(struct qcom_nand_host *host, int page_addr)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	u32 ers_cmd = OP_BLOCK_ERASE | PAGE_ACC | LAST_PAGE;
+	u32 addr1 = 0x0;
+
+	if (nandc->props->is_serial_nand) {
+		ers_cmd |= (SPI_WP | SPI_HOLD | SPI_TRANSFER_MODE_x1);
+		addr1 = (page_addr >> 16) & 0xffff;
+		page_addr <<= 16;
+	}
+	nandc_set_reg(chip, NAND_FLASH_CMD, ers_cmd);
+	nandc_set_reg(chip, NAND_ADDR0, page_addr);
+	nandc_set_reg(chip, NAND_ADDR1, addr1);
+	nandc_set_reg(chip, NAND_DEV0_CFG0,
+		      host->cfg0_raw & ~(7 << CW_PER_PAGE));
+	nandc_set_reg(chip, NAND_DEV0_CFG1, host->cfg1_raw);
+	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
+	nandc_set_reg(chip, NAND_FLASH_STATUS, host->clrflashstatus);
+	nandc_set_reg(chip, NAND_READ_STATUS, host->clrreadstatus);
+
+	write_reg_dma(nandc, NAND_FLASH_CMD, 3, NAND_BAM_NEXT_SGL);
+	write_reg_dma(nandc, NAND_DEV0_CFG0, 2, NAND_BAM_NEXT_SGL);
+	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+
+	read_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);
+
+	write_reg_dma(nandc, NAND_FLASH_STATUS, 1, 0);
+	write_reg_dma(nandc, NAND_READ_STATUS, 1, NAND_BAM_NEXT_SGL);
+
+	return 0;
+}
+
+/* sets up descriptors for NAND_CMD_READID */
+static int read_id(struct qcom_nand_host *host, int column)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	u32 cmd = OP_FETCH_ID;
+
+	if (column == -1)
+		return 0;
+
+	if (nandc->props->is_serial_nand) {
+		cmd |= (SPI_WP | SPI_HOLD | SPI_TRANSFER_MODE_x1);
+		/* For spi nand read 2-bytes id only
+		 * else if nandc->buf_count == 4; then the id value
+		 * will repeat and the SLC device will be detect as MLC.
+		 * by nand base layer
+		 * so overwrite the nandc->buf_count == 2;
+		 */
+		nandc->buf_count = 2;
+	}
+
+	nandc_set_reg(chip, NAND_FLASH_CMD, cmd);
+	nandc_set_reg(chip, NAND_ADDR0, column);
+	nandc_set_reg(chip, NAND_ADDR1, 0);
+	nandc_set_reg(chip, NAND_FLASH_CHIP_SELECT,
+		      nandc->props->is_bam ? 0 : DM_EN);
+	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
+
+	write_reg_dma(nandc, NAND_FLASH_CMD, 4, NAND_BAM_NEXT_SGL);
+	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+
+	read_reg_dma(nandc, NAND_READ_ID, 1, NAND_BAM_NEXT_SGL);
+
+	if (nandc->props->is_serial_nand &&
+		((le32_to_cpu(nandc->reg_read_buf[0]) & 0xFF) ==
+		NAND_MID_WINBOND)) {
+		nandc->buf_count = 4;
+	}
+
+	return 0;
+}
+
+/* sets up descriptors for NAND_CMD_RESET */
+static int reset(struct qcom_nand_host *host)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	int cmd_rst;
+
+	cmd_rst = OP_RESET_DEVICE;
+	if (nandc->props->is_serial_nand)
+		cmd_rst |= (SPI_WP | SPI_HOLD | SPI_TRANSFER_MODE_x1);
+
+	nandc_set_reg(chip, NAND_FLASH_CMD, cmd_rst);
+	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
+
+	write_reg_dma(nandc, NAND_FLASH_CMD, 1, NAND_BAM_NEXT_SGL);
+	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+
+	read_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);
+
+	return 0;
+}
+
 /* helpers to submit/free our list of dma descriptors */
 static int submit_descs(struct qcom_nand_controller *nandc)
 {
-	struct desc_info *desc, *n;
+	struct desc_info *desc;
 	dma_cookie_t cookie = 0;
 	struct bam_transaction *bam_txn = nandc->bam_txn;
-	int ret = 0;
+	int r;
 
 	if (nandc->props->is_bam) {
 		if (bam_txn->rx_sgl_pos > bam_txn->rx_sgl_start) {
-			ret = prepare_bam_async_desc(nandc, nandc->rx_chan, 0);
-			if (ret)
-				goto err_unmap_free_desc;
+			r = prepare_bam_async_desc(nandc, nandc->rx_chan, 0);
+			if (r)
+				return r;
 		}
 
 		if (bam_txn->tx_sgl_pos > bam_txn->tx_sgl_start) {
-			ret = prepare_bam_async_desc(nandc, nandc->tx_chan,
+			r = prepare_bam_async_desc(nandc, nandc->tx_chan,
 						   DMA_PREP_INTERRUPT);
-			if (ret)
-				goto err_unmap_free_desc;
+			if (r)
+				return r;
 		}
 
 		if (bam_txn->cmd_sgl_pos > bam_txn->cmd_sgl_start) {
-			ret = prepare_bam_async_desc(nandc, nandc->cmd_chan,
+			r = prepare_bam_async_desc(nandc, nandc->cmd_chan,
 						   DMA_PREP_CMD);
-			if (ret)
-				goto err_unmap_free_desc;
+			if (r)
+				return r;
+		}
+		if (nandc->props->qpic_v2) {
+			if (bam_txn->sts_sgl_pos > bam_txn->sts_sgl_start) {
+				r = prepare_bam_async_desc(nandc, nandc->sts_chan, 0);
+				if (r)
+					return r;
+			}
 		}
 	}
 
@@ -1348,20 +1701,24 @@ static int submit_descs(struct qcom_nand_controller *nandc)
 		dma_async_issue_pending(nandc->tx_chan);
 		dma_async_issue_pending(nandc->rx_chan);
 		dma_async_issue_pending(nandc->cmd_chan);
+		if (nandc->props->qpic_v2)
+			dma_async_issue_pending(nandc->sts_chan);
 
 		if (!wait_for_completion_timeout(&bam_txn->txn_done,
 						 QPIC_NAND_COMPLETION_TIMEOUT))
-			ret = -ETIMEDOUT;
+			return -ETIMEDOUT;
 	} else {
 		if (dma_sync_wait(nandc->chan, cookie) != DMA_COMPLETE)
-			ret = -ETIMEDOUT;
+			return -ETIMEDOUT;
 	}
 
-err_unmap_free_desc:
-	/*
-	 * Unmap the dma sg_list and free the desc allocated by both
-	 * prepare_bam_async_desc() and prep_adm_dma_desc() functions.
-	 */
+	return 0;
+}
+
+static void free_descs(struct qcom_nand_controller *nandc)
+{
+	struct desc_info *desc, *n;
+
 	list_for_each_entry_safe(desc, n, &nandc->desc_list, node) {
 		list_del(&desc->node);
 
@@ -1374,8 +1731,6 @@ static int submit_descs(struct qcom_nand_controller *nandc)
 
 		kfree(desc);
 	}
-
-	return ret;
 }
 
 /* reset the register read buffer for next NAND operation */
@@ -1385,6 +1740,153 @@ static void clear_read_regs(struct qcom_nand_controller *nandc)
 	nandc_read_buffer_sync(nandc, false);
 }
 
+static void pre_command(struct qcom_nand_host *host, int command)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+
+	nandc->buf_count = 0;
+	nandc->buf_start = 0;
+	host->use_ecc = false;
+	host->last_command = command;
+
+	clear_read_regs(nandc);
+
+	if (command == NAND_CMD_RESET || command == NAND_CMD_READID ||
+	    command == NAND_CMD_PARAM || command == NAND_CMD_ERASE1 ||
+		command == NAND_CMD_READID_SERIAL)
+		clear_bam_transaction(nandc);
+}
+
+/*
+ * this is called after NAND_CMD_PAGEPROG and NAND_CMD_ERASE1 to set our
+ * privately maintained status byte, this status byte can be read after
+ * NAND_CMD_STATUS is called
+ */
+static void parse_erase_write_errors(struct qcom_nand_host *host, int command)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	struct nand_ecc_ctrl *ecc = &chip->ecc;
+	int num_cw;
+	int i;
+
+	num_cw = command == NAND_CMD_PAGEPROG ? ecc->steps : 1;
+	nandc_read_buffer_sync(nandc, true);
+
+	for (i = 0; i < num_cw; i++) {
+		u32 flash_status = le32_to_cpu(nandc->reg_read_buf[i]);
+
+		if (flash_status & FS_MPU_ERR)
+			host->status &= ~NAND_STATUS_WP;
+
+		if (flash_status & FS_OP_ERR || (i == (num_cw - 1) &&
+						 (flash_status &
+						  FS_DEVICE_STS_ERR)))
+			host->status |= NAND_STATUS_FAIL;
+	}
+}
+
+static void post_command(struct qcom_nand_host *host, int command)
+{
+	struct nand_chip *chip = &host->chip;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+
+	switch (command) {
+	case NAND_CMD_READID:
+		nandc_read_buffer_sync(nandc, true);
+		memcpy(nandc->data_buffer, nandc->reg_read_buf,
+		       nandc->buf_count);
+		break;
+	case NAND_CMD_PAGEPROG:
+	case NAND_CMD_ERASE1:
+		parse_erase_write_errors(host, command);
+		break;
+	default:
+		break;
+	}
+}
+
+/*
+ * Implements chip->legacy.cmdfunc. It's  only used for a limited set of
+ * commands. The rest of the commands wouldn't be called by upper layers.
+ * For example, NAND_CMD_READOOB would never be called because we have our own
+ * versions of read_oob ops for nand_ecc_ctrl.
+ */
+static void qcom_nandc_command(struct nand_chip *chip, unsigned int command,
+			       int column, int page_addr)
+{
+	struct qcom_nand_host *host = to_qcom_nand_host(chip);
+	struct nand_ecc_ctrl *ecc = &chip->ecc;
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	bool wait = false;
+	int ret = 0;
+
+	pre_command(host, command);
+
+	switch (command) {
+	case NAND_CMD_RESET:
+		ret = reset(host);
+		wait = true;
+		break;
+
+	case NAND_CMD_READID:
+		nandc->buf_count = 4;
+		ret = read_id(host, column);
+		wait = true;
+		break;
+
+	case NAND_CMD_PARAM:
+		ret = nandc_param(host);
+		wait = true;
+		break;
+
+	case NAND_CMD_ERASE1:
+		ret = erase_block(host, page_addr);
+		wait = true;
+		break;
+
+	case NAND_CMD_READ0:
+		/* we read the entire page for now */
+		WARN_ON(column != 0);
+
+		host->use_ecc = true;
+		set_address(host, 0, page_addr);
+		update_rw_regs(host, ecc->steps, true, 0);
+		break;
+
+	case NAND_CMD_SEQIN:
+		WARN_ON(column != 0);
+		set_address(host, 0, page_addr);
+		break;
+
+	case NAND_CMD_PAGEPROG:
+	case NAND_CMD_STATUS:
+	case NAND_CMD_NONE:
+	default:
+		break;
+	}
+
+	if (ret) {
+		dev_err(nandc->dev, "failure executing command %d\n",
+			command);
+		free_descs(nandc);
+		return;
+	}
+
+	if (wait) {
+		ret = submit_descs(nandc);
+		if (ret)
+			dev_err(nandc->dev,
+				"failure submitting descs for command %d\n",
+				command);
+	}
+
+	free_descs(nandc);
+
+	post_command(host, command);
+}
+
 /*
  * when using BCH ECC, the HW flags an error in NAND_FLASH_STATUS if it read
  * an erased CW, and reports an erased CW in NAND_ERASED_CW_DETECT_STATUS.
@@ -1471,9 +1973,6 @@ qcom_nandc_read_cw_raw(struct mtd_info *mtd, struct nand_chip *chip,
 	int raw_cw = cw;
 
 	nand_read_page_op(chip, page, 0, NULL, 0);
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
-	clear_read_regs(nandc);
 	host->use_ecc = false;
 
 	if (nandc->props->qpic_v2)
@@ -1524,6 +2023,7 @@ qcom_nandc_read_cw_raw(struct mtd_info *mtd, struct nand_chip *chip,
 	read_data_dma(nandc, reg_off, oob_buf + oob_size1, oob_size2, 0);
 
 	ret = submit_descs(nandc);
+	free_descs(nandc);
 	if (ret) {
 		dev_err(nandc->dev, "failure to read raw cw %d\n", cw);
 		return ret;
@@ -1556,7 +2056,7 @@ check_for_erased_page(struct qcom_nand_host *host, u8 *data_buf,
 	struct mtd_info *mtd = nand_to_mtd(chip);
 	struct nand_ecc_ctrl *ecc = &chip->ecc;
 	u8 *cw_data_buf, *cw_oob_buf;
-	int cw, data_size, oob_size, ret;
+	int cw, data_size, oob_size, ret = 0;
 
 	if (!data_buf)
 		data_buf = nand_get_data_buf(chip);
@@ -1718,6 +2218,8 @@ static int read_page_ecc(struct qcom_nand_host *host, u8 *data_buf,
 	struct nand_ecc_ctrl *ecc = &chip->ecc;
 	u8 *data_buf_start = data_buf, *oob_buf_start = oob_buf;
 	int i, ret;
+	__le32 *status_buf_start = nandc->status_buf;
+	__le32 *status_buf_cw = nandc->status_buf;
 
 	config_nand_page_read(chip);
 
@@ -1753,6 +2255,11 @@ static int read_page_ecc(struct qcom_nand_host *host, u8 *data_buf,
 			read_data_dma(nandc, FLASH_BUF_ACC, data_buf,
 				      data_size, 0);
 
+		if (nandc->props->qpic_v2 && nandc->props->page_scope) {
+			read_status_data_dma(nandc, FLASH_BUF_ACC, (void *)status_buf_cw,
+					MAX_STATUS_REG, 0);
+			status_buf_cw += (MAX_STATUS_REG / sizeof(u32));
+		}
 		/*
 		 * when ecc is enabled, the controller doesn't read the real
 		 * or dummy bad block markers in each chunk. To maintain a
@@ -1777,10 +2284,14 @@ static int read_page_ecc(struct qcom_nand_host *host, u8 *data_buf,
 	}
 
 	ret = submit_descs(nandc);
+	free_descs(nandc);
+
 	if (ret) {
 		dev_err(nandc->dev, "failure to read page/oob\n");
 		return ret;
 	}
+	if (nandc->props->qpic_v2 && nandc->props->page_scope)
+		memmove(nandc->reg_read_buf, status_buf_start, nandc->sts_buf_size);
 
 	return parse_read_errors(host, data_buf_start, oob_buf_start, page);
 }
@@ -1815,6 +2326,8 @@ static int copy_last_cw(struct qcom_nand_host *host, int page)
 	if (ret)
 		dev_err(nandc->dev, "failed to copy last codeword\n");
 
+	free_descs(nandc);
+
 	return ret;
 }
 
@@ -1882,25 +2395,17 @@ static void qcom_nandc_codeword_fixup(struct qcom_nand_host *host, int page)
 }
 
 /* implements ecc->read_page() */
-static int qcom_nandc_read_page(struct nand_chip *chip, u8 *buf,
+static int qcom_nandc_read_page(struct nand_chip *chip, uint8_t *buf,
 				int oob_required, int page)
 {
 	struct qcom_nand_host *host = to_qcom_nand_host(chip);
 	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	struct nand_ecc_ctrl *ecc = &chip->ecc;
 	u8 *data_buf, *oob_buf = NULL;
 
 	if (host->nr_boot_partitions)
 		qcom_nandc_codeword_fixup(host, page);
 
 	nand_read_page_op(chip, page, 0, NULL, 0);
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
-	host->use_ecc = true;
-	clear_read_regs(nandc);
-	set_address(host, 0, page);
-	update_rw_regs(host, ecc->steps, true, 0);
-
 	data_buf = buf;
 	oob_buf = oob_required ? chip->oob_poi : NULL;
 
@@ -1910,7 +2415,7 @@ static int qcom_nandc_read_page(struct nand_chip *chip, u8 *buf,
 }
 
 /* implements ecc->read_page_raw() */
-static int qcom_nandc_read_page_raw(struct nand_chip *chip, u8 *buf,
+static int qcom_nandc_read_page_raw(struct nand_chip *chip, uint8_t *buf,
 				    int oob_required, int page)
 {
 	struct mtd_info *mtd = nand_to_mtd(chip);
@@ -1956,7 +2461,7 @@ static int qcom_nandc_read_oob(struct nand_chip *chip, int page)
 }
 
 /* implements ecc->write_page() */
-static int qcom_nandc_write_page(struct nand_chip *chip, const u8 *buf,
+static int qcom_nandc_write_page(struct nand_chip *chip, const uint8_t *buf,
 				 int oob_required, int page)
 {
 	struct qcom_nand_host *host = to_qcom_nand_host(chip);
@@ -1970,9 +2475,6 @@ static int qcom_nandc_write_page(struct nand_chip *chip, const u8 *buf,
 
 	nand_prog_page_begin_op(chip, page, 0, NULL, 0);
 
-	set_address(host, 0, page);
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
 	clear_read_regs(nandc);
 	clear_bam_transaction(nandc);
 
@@ -1995,6 +2497,7 @@ static int qcom_nandc_write_page(struct nand_chip *chip, const u8 *buf,
 			oob_size = ecc->bytes;
 		}
 
+
 		write_data_dma(nandc, FLASH_BUF_ACC, data_buf, data_size,
 			       i == (ecc->steps - 1) ? NAND_BAM_NO_EOT : 0);
 
@@ -2019,17 +2522,20 @@ static int qcom_nandc_write_page(struct nand_chip *chip, const u8 *buf,
 	}
 
 	ret = submit_descs(nandc);
-	if (ret) {
+	if (ret)
 		dev_err(nandc->dev, "failure to write page\n");
-		return ret;
-	}
 
-	return nand_prog_page_end_op(chip);
+	free_descs(nandc);
+
+	if (!ret)
+		ret = nand_prog_page_end_op(chip);
+
+	return ret;
 }
 
 /* implements ecc->write_page_raw() */
 static int qcom_nandc_write_page_raw(struct nand_chip *chip,
-				     const u8 *buf, int oob_required,
+				     const uint8_t *buf, int oob_required,
 				     int page)
 {
 	struct mtd_info *mtd = nand_to_mtd(chip);
@@ -2092,12 +2598,15 @@ static int qcom_nandc_write_page_raw(struct nand_chip *chip,
 	}
 
 	ret = submit_descs(nandc);
-	if (ret) {
+	if (ret)
 		dev_err(nandc->dev, "failure to write raw page\n");
-		return ret;
-	}
 
-	return nand_prog_page_end_op(chip);
+	free_descs(nandc);
+
+	if (!ret)
+		ret = nand_prog_page_end_op(chip);
+
+	return ret;
 }
 
 /*
@@ -2141,9 +2650,12 @@ static int qcom_nandc_write_oob(struct nand_chip *chip, int page)
 	config_nand_cw_write(chip);
 
 	ret = submit_descs(nandc);
+
+	free_descs(nandc);
+
 	if (ret) {
 		dev_err(nandc->dev, "failure to write oob\n");
-		return ret;
+		return -EIO;
 	}
 
 	return nand_prog_page_end_op(chip);
@@ -2217,15 +2729,76 @@ static int qcom_nandc_block_markbad(struct nand_chip *chip, loff_t ofs)
 	config_nand_cw_write(chip);
 
 	ret = submit_descs(nandc);
+
+	free_descs(nandc);
+
 	if (ret) {
 		dev_err(nandc->dev, "failure to update BBM\n");
-		return ret;
+		return -EIO;
 	}
 
 	return nand_prog_page_end_op(chip);
 }
 
 /*
+ * the three functions below implement chip->legacy.read_byte(),
+ * chip->legacy.read_buf() and chip->legacy.write_buf() respectively. these
+ * aren't used for reading/writing page data, they are used for smaller data
+ * like reading	id, status etc
+ */
+static uint8_t qcom_nandc_read_byte(struct nand_chip *chip)
+{
+	struct qcom_nand_host *host = to_qcom_nand_host(chip);
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	u8 *buf = nandc->data_buffer;
+	u8 ret = 0x0;
+
+	if (host->last_command == NAND_CMD_STATUS) {
+		ret = host->status;
+
+		host->status = NAND_STATUS_READY | NAND_STATUS_WP;
+
+		return ret;
+	}
+
+	if (nandc->buf_start < nandc->buf_count)
+		ret = buf[nandc->buf_start++];
+
+	return ret;
+}
+
+static void qcom_nandc_read_buf(struct nand_chip *chip, uint8_t *buf, int len)
+{
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	int real_len = min_t(size_t, len, nandc->buf_count - nandc->buf_start);
+
+	memcpy(buf, nandc->data_buffer + nandc->buf_start, real_len);
+	nandc->buf_start += real_len;
+}
+
+static void qcom_nandc_write_buf(struct nand_chip *chip, const uint8_t *buf,
+				 int len)
+{
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	int real_len = min_t(size_t, len, nandc->buf_count - nandc->buf_start);
+
+	memcpy(nandc->data_buffer + nandc->buf_start, buf, real_len);
+
+	nandc->buf_start += real_len;
+}
+
+/* we support only one external chip for now */
+static void qcom_nandc_select_chip(struct nand_chip *chip, int chipnr)
+{
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+
+	if (chipnr <= 0)
+		return;
+
+	dev_warn(nandc->dev, "invalid chip select\n");
+}
+
+/*
  * NAND controller page layout info
  *
  * Layout with ECC enabled:
@@ -2333,7 +2906,7 @@ static int qcom_nand_ooblayout_ecc(struct mtd_info *mtd, int section,
 }
 
 static int qcom_nand_ooblayout_free(struct mtd_info *mtd, int section,
-				    struct mtd_oob_region *oobregion)
+				     struct mtd_oob_region *oobregion)
 {
 	struct nand_chip *chip = mtd_to_nand(mtd);
 	struct qcom_nand_host *host = to_qcom_nand_host(chip);
@@ -2358,7 +2931,6 @@ qcom_nandc_calc_ecc_bytes(int step_size, int strength)
 {
 	return strength == 4 ? 12 : 16;
 }
-
 NAND_ECC_CAPS_SINGLE(qcom_nandc_ecc_caps, qcom_nandc_calc_ecc_bytes,
 		     NANDC_STEP_SIZE, 4, 8);
 
@@ -2371,11 +2943,14 @@ static int qcom_nand_attach_chip(struct nand_chip *chip)
 	int cwperpage, bad_block_byte, ret;
 	bool wide_bus;
 	int ecc_mode = 1;
+	int num_addr_cycle = 5, dsbl_sts_aftr_write = 0;
+	int wr_rd_bsy_gap = 2, recovery_cycle = 7;
 
 	/* controller only supports 512 bytes data steps */
 	ecc->size = NANDC_STEP_SIZE;
 	wide_bus = chip->options & NAND_BUSWIDTH_16 ? true : false;
 	cwperpage = mtd->writesize / NANDC_STEP_SIZE;
+	ecc->strength = mtd->oobsize >= 128 ? 8 : 4;
 
 	/*
 	 * Each CW has 4 available OOB bytes which will be protected with ECC
@@ -2485,33 +3060,43 @@ static int qcom_nand_attach_chip(struct nand_chip *chip)
 	host->cw_size = host->cw_data + ecc->bytes;
 	bad_block_byte = mtd->writesize - host->cw_size * (cwperpage - 1) + 1;
 
+	/* For QSPI serial nand QPIC config register value got changed
+	 * so configure the new value for qspi serial nand
+	 */
+	if (nandc->props->is_serial_nand) {
+		num_addr_cycle = 3;
+		dsbl_sts_aftr_write = 1;
+		wr_rd_bsy_gap = 20;
+		recovery_cycle = 0;
+	}
+
 	host->cfg0 = (cwperpage - 1) << CW_PER_PAGE
 				| host->cw_data << UD_SIZE_BYTES
-				| 0 << DISABLE_STATUS_AFTER_WRITE
-				| 5 << NUM_ADDR_CYCLES
+				| dsbl_sts_aftr_write << DISABLE_STATUS_AFTER_WRITE
+				| num_addr_cycle << NUM_ADDR_CYCLES
 				| host->ecc_bytes_hw << ECC_PARITY_SIZE_BYTES_RS
 				| 0 << STATUS_BFR_READ
 				| 1 << SET_RD_MODE_AFTER_STATUS
 				| host->spare_bytes << SPARE_SIZE_BYTES;
 
-	host->cfg1 = 7 << NAND_RECOVERY_CYCLES
+	host->cfg1 = recovery_cycle << NAND_RECOVERY_CYCLES
 				| 0 <<  CS_ACTIVE_BSY
 				| bad_block_byte << BAD_BLOCK_BYTE_NUM
 				| 0 << BAD_BLOCK_IN_SPARE_AREA
-				| 2 << WR_RD_BSY_GAP
+				| wr_rd_bsy_gap << WR_RD_BSY_GAP
 				| wide_bus << WIDE_FLASH
 				| host->bch_enabled << ENABLE_BCH_ECC;
 
 	host->cfg0_raw = (cwperpage - 1) << CW_PER_PAGE
 				| host->cw_size << UD_SIZE_BYTES
-				| 5 << NUM_ADDR_CYCLES
+				| num_addr_cycle << NUM_ADDR_CYCLES
 				| 0 << SPARE_SIZE_BYTES;
 
-	host->cfg1_raw = 7 << NAND_RECOVERY_CYCLES
+	host->cfg1_raw = recovery_cycle << NAND_RECOVERY_CYCLES
 				| 0 << CS_ACTIVE_BSY
 				| 17 << BAD_BLOCK_BYTE_NUM
 				| 1 << BAD_BLOCK_IN_SPARE_AREA
-				| 2 << WR_RD_BSY_GAP
+				| wr_rd_bsy_gap << WR_RD_BSY_GAP
 				| wide_bus << WIDE_FLASH
 				| 1 << DEV0_CFG1_ECC_DISABLE;
 
@@ -2541,478 +3126,8 @@ static int qcom_nand_attach_chip(struct nand_chip *chip)
 	return 0;
 }
 
-static int qcom_op_cmd_mapping(struct nand_chip *chip, u8 opcode,
-			       struct qcom_op *q_op)
-{
-	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	struct qcom_nand_host *host = to_qcom_nand_host(chip);
-	int cmd;
-
-	switch (opcode) {
-	case NAND_CMD_RESET:
-		cmd = OP_RESET_DEVICE;
-		break;
-	case NAND_CMD_READID:
-		cmd = OP_FETCH_ID;
-		break;
-	case NAND_CMD_PARAM:
-		if (nandc->props->qpic_v2)
-			cmd = OP_PAGE_READ_ONFI_READ;
-		else
-			cmd = OP_PAGE_READ;
-		break;
-	case NAND_CMD_ERASE1:
-	case NAND_CMD_ERASE2:
-		cmd = OP_BLOCK_ERASE;
-		break;
-	case NAND_CMD_STATUS:
-		cmd = OP_CHECK_STATUS;
-		break;
-	case NAND_CMD_PAGEPROG:
-		cmd = OP_PROGRAM_PAGE;
-		q_op->flag = OP_PROGRAM_PAGE;
-		nandc->exec_opwrite = true;
-		break;
-	case NAND_CMD_READ0:
-	case NAND_CMD_READSTART:
-		if (host->use_ecc)
-			cmd = OP_PAGE_READ_WITH_ECC;
-		else
-			cmd = OP_PAGE_READ;
-		break;
-	default:
-		dev_err(nandc->dev, "Opcode not supported: %u\n", opcode);
-		return -EOPNOTSUPP;
-	}
-
-	return cmd;
-}
-
-/* NAND framework ->exec_op() hooks and related helpers */
-static int qcom_parse_instructions(struct nand_chip *chip,
-				    const struct nand_subop *subop,
-				    struct qcom_op *q_op)
-{
-	const struct nand_op_instr *instr = NULL;
-	unsigned int op_id;
-	int i, ret;
-
-	for (op_id = 0; op_id < subop->ninstrs; op_id++) {
-		unsigned int offset, naddrs;
-		const u8 *addrs;
-
-		instr = &subop->instrs[op_id];
-
-		switch (instr->type) {
-		case NAND_OP_CMD_INSTR:
-			ret = qcom_op_cmd_mapping(chip, instr->ctx.cmd.opcode, q_op);
-			if (ret < 0)
-				return ret;
-
-			q_op->cmd_reg = ret;
-			q_op->rdy_delay_ns = instr->delay_ns;
-			break;
-
-		case NAND_OP_ADDR_INSTR:
-			offset = nand_subop_get_addr_start_off(subop, op_id);
-			naddrs = nand_subop_get_num_addr_cyc(subop, op_id);
-			addrs = &instr->ctx.addr.addrs[offset];
-
-			for (i = 0; i < min_t(unsigned int, 4, naddrs); i++)
-				q_op->addr1_reg |= addrs[i] << (i * 8);
-
-			if (naddrs > 4)
-				q_op->addr2_reg |= addrs[4];
-
-			q_op->rdy_delay_ns = instr->delay_ns;
-			break;
-
-		case NAND_OP_DATA_IN_INSTR:
-			q_op->data_instr = instr;
-			q_op->data_instr_idx = op_id;
-			q_op->rdy_delay_ns = instr->delay_ns;
-			fallthrough;
-		case NAND_OP_DATA_OUT_INSTR:
-			q_op->rdy_delay_ns = instr->delay_ns;
-			break;
-
-		case NAND_OP_WAITRDY_INSTR:
-			q_op->rdy_timeout_ms = instr->ctx.waitrdy.timeout_ms;
-			q_op->rdy_delay_ns = instr->delay_ns;
-			break;
-		}
-	}
-
-	return 0;
-}
-
-static void qcom_delay_ns(unsigned int ns)
-{
-	if (!ns)
-		return;
-
-	if (ns < 10000)
-		ndelay(ns);
-	else
-		udelay(DIV_ROUND_UP(ns, 1000));
-}
-
-static int qcom_wait_rdy_poll(struct nand_chip *chip, unsigned int time_ms)
-{
-	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	unsigned long start = jiffies + msecs_to_jiffies(time_ms);
-	u32 flash;
-
-	nandc_read_buffer_sync(nandc, true);
-
-	do {
-		flash = le32_to_cpu(nandc->reg_read_buf[0]);
-		if (flash & FS_READY_BSY_N)
-			return 0;
-		cpu_relax();
-	} while (time_after(start, jiffies));
-
-	dev_err(nandc->dev, "Timeout waiting for device to be ready:0x%08x\n", flash);
-
-	return -ETIMEDOUT;
-}
-
-static int qcom_read_status_exec(struct nand_chip *chip,
-				 const struct nand_subop *subop)
-{
-	struct qcom_nand_host *host = to_qcom_nand_host(chip);
-	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	struct nand_ecc_ctrl *ecc = &chip->ecc;
-	struct qcom_op q_op = {};
-	const struct nand_op_instr *instr = NULL;
-	unsigned int op_id = 0;
-	unsigned int len = 0;
-	int ret, num_cw, i;
-	u32 flash_status;
-
-	host->status = NAND_STATUS_READY | NAND_STATUS_WP;
-
-	ret = qcom_parse_instructions(chip, subop, &q_op);
-	if (ret)
-		return ret;
-
-	num_cw = nandc->exec_opwrite ? ecc->steps : 1;
-	nandc->exec_opwrite = false;
-
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
-	host->use_ecc = false;
-
-	clear_read_regs(nandc);
-	clear_bam_transaction(nandc);
-
-	nandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);
-	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
-
-	write_reg_dma(nandc, NAND_FLASH_CMD, 1, NAND_BAM_NEXT_SGL);
-	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
-	read_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);
-
-	ret = submit_descs(nandc);
-	if (ret) {
-		dev_err(nandc->dev, "failure in submitting status descriptor\n");
-		goto err_out;
-	}
-
-	nandc_read_buffer_sync(nandc, true);
-
-	for (i = 0; i < num_cw; i++) {
-		flash_status = le32_to_cpu(nandc->reg_read_buf[i]);
-
-		if (flash_status & FS_MPU_ERR)
-			host->status &= ~NAND_STATUS_WP;
-
-		if (flash_status & FS_OP_ERR ||
-		    (i == (num_cw - 1) && (flash_status & FS_DEVICE_STS_ERR)))
-			host->status |= NAND_STATUS_FAIL;
-	}
-
-	flash_status = host->status;
-	instr = q_op.data_instr;
-	op_id = q_op.data_instr_idx;
-	len = nand_subop_get_data_len(subop, op_id);
-	memcpy(instr->ctx.data.buf.in, &flash_status, len);
-
-err_out:
-	return ret;
-}
-
-static int qcom_read_id_type_exec(struct nand_chip *chip, const struct nand_subop *subop)
-{
-	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	struct qcom_nand_host *host = to_qcom_nand_host(chip);
-	struct qcom_op q_op = {};
-	const struct nand_op_instr *instr = NULL;
-	unsigned int op_id = 0;
-	unsigned int len = 0;
-	int ret;
-
-	ret = qcom_parse_instructions(chip, subop, &q_op);
-	if (ret)
-		return ret;
-
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
-	host->use_ecc = false;
-
-	clear_read_regs(nandc);
-	clear_bam_transaction(nandc);
-
-	nandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);
-	nandc_set_reg(chip, NAND_ADDR0, q_op.addr1_reg);
-	nandc_set_reg(chip, NAND_ADDR1, q_op.addr2_reg);
-	nandc_set_reg(chip, NAND_FLASH_CHIP_SELECT,
-		      nandc->props->is_bam ? 0 : DM_EN);
-
-	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
-
-	write_reg_dma(nandc, NAND_FLASH_CMD, 4, NAND_BAM_NEXT_SGL);
-	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
-
-	read_reg_dma(nandc, NAND_READ_ID, 1, NAND_BAM_NEXT_SGL);
-
-	ret = submit_descs(nandc);
-	if (ret) {
-		dev_err(nandc->dev, "failure in submitting read id descriptor\n");
-		goto err_out;
-	}
-
-	instr = q_op.data_instr;
-	op_id = q_op.data_instr_idx;
-	len = nand_subop_get_data_len(subop, op_id);
-
-	nandc_read_buffer_sync(nandc, true);
-	memcpy(instr->ctx.data.buf.in, nandc->reg_read_buf, len);
-
-err_out:
-	return ret;
-}
-
-static int qcom_misc_cmd_type_exec(struct nand_chip *chip, const struct nand_subop *subop)
-{
-	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	struct qcom_nand_host *host = to_qcom_nand_host(chip);
-	struct qcom_op q_op = {};
-	int ret;
-	int instrs = 1;
-
-	ret = qcom_parse_instructions(chip, subop, &q_op);
-	if (ret)
-		return ret;
-
-	if (q_op.flag == OP_PROGRAM_PAGE) {
-		goto wait_rdy;
-	} else if (q_op.cmd_reg == OP_BLOCK_ERASE) {
-		q_op.cmd_reg |= PAGE_ACC | LAST_PAGE;
-		nandc_set_reg(chip, NAND_ADDR0, q_op.addr1_reg);
-		nandc_set_reg(chip, NAND_ADDR1, q_op.addr2_reg);
-		nandc_set_reg(chip, NAND_DEV0_CFG0,
-			      host->cfg0_raw & ~(7 << CW_PER_PAGE));
-		nandc_set_reg(chip, NAND_DEV0_CFG1, host->cfg1_raw);
-		instrs = 3;
-	} else if (q_op.cmd_reg != OP_RESET_DEVICE) {
-		return 0;
-	}
-
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
-	host->use_ecc = false;
-
-	clear_read_regs(nandc);
-	clear_bam_transaction(nandc);
-
-	nandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);
-	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
-
-	write_reg_dma(nandc, NAND_FLASH_CMD, instrs, NAND_BAM_NEXT_SGL);
-	if (q_op.cmd_reg == OP_BLOCK_ERASE)
-		write_reg_dma(nandc, NAND_DEV0_CFG0, 2, NAND_BAM_NEXT_SGL);
-
-	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
-	read_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);
-
-	ret = submit_descs(nandc);
-	if (ret) {
-		dev_err(nandc->dev, "failure in submitting misc descriptor\n");
-		goto err_out;
-	}
-
-wait_rdy:
-	qcom_delay_ns(q_op.rdy_delay_ns);
-	ret = qcom_wait_rdy_poll(chip, q_op.rdy_timeout_ms);
-
-err_out:
-	return ret;
-}
-
-static int qcom_param_page_type_exec(struct nand_chip *chip,  const struct nand_subop *subop)
-{
-	struct qcom_nand_host *host = to_qcom_nand_host(chip);
-	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
-	struct qcom_op q_op = {};
-	const struct nand_op_instr *instr = NULL;
-	unsigned int op_id = 0;
-	unsigned int len = 0;
-	int ret;
-
-	ret = qcom_parse_instructions(chip, subop, &q_op);
-	if (ret)
-		return ret;
-
-	q_op.cmd_reg |= PAGE_ACC | LAST_PAGE;
-
-	nandc->buf_count = 0;
-	nandc->buf_start = 0;
-	host->use_ecc = false;
-	clear_read_regs(nandc);
-	clear_bam_transaction(nandc);
-
-	nandc_set_reg(chip, NAND_FLASH_CMD, q_op.cmd_reg);
-
-	nandc_set_reg(chip, NAND_ADDR0, 0);
-	nandc_set_reg(chip, NAND_ADDR1, 0);
-	nandc_set_reg(chip, NAND_DEV0_CFG0, 0 << CW_PER_PAGE
-					| 512 << UD_SIZE_BYTES
-					| 5 << NUM_ADDR_CYCLES
-					| 0 << SPARE_SIZE_BYTES);
-	nandc_set_reg(chip, NAND_DEV0_CFG1, 7 << NAND_RECOVERY_CYCLES
-					| 0 << CS_ACTIVE_BSY
-					| 17 << BAD_BLOCK_BYTE_NUM
-					| 1 << BAD_BLOCK_IN_SPARE_AREA
-					| 2 << WR_RD_BSY_GAP
-					| 0 << WIDE_FLASH
-					| 1 << DEV0_CFG1_ECC_DISABLE);
-	if (!nandc->props->qpic_v2)
-		nandc_set_reg(chip, NAND_EBI2_ECC_BUF_CFG, 1 << ECC_CFG_ECC_DISABLE);
-
-	/* configure CMD1 and VLD for ONFI param probing in QPIC v1 */
-	if (!nandc->props->qpic_v2) {
-		nandc_set_reg(chip, NAND_DEV_CMD_VLD,
-			      (nandc->vld & ~READ_START_VLD));
-		nandc_set_reg(chip, NAND_DEV_CMD1,
-			      (nandc->cmd1 & ~(0xFF << READ_ADDR))
-			      | NAND_CMD_PARAM << READ_ADDR);
-	}
-
-	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
-
-	if (!nandc->props->qpic_v2) {
-		nandc_set_reg(chip, NAND_DEV_CMD1_RESTORE, nandc->cmd1);
-		nandc_set_reg(chip, NAND_DEV_CMD_VLD_RESTORE, nandc->vld);
-	}
-
-	instr = q_op.data_instr;
-	op_id = q_op.data_instr_idx;
-	len = nand_subop_get_data_len(subop, op_id);
-
-	nandc_set_read_loc(chip, 0, 0, 0, len, 1);
-
-	if (!nandc->props->qpic_v2) {
-		write_reg_dma(nandc, NAND_DEV_CMD_VLD, 1, 0);
-		write_reg_dma(nandc, NAND_DEV_CMD1, 1, NAND_BAM_NEXT_SGL);
-	}
-
-	nandc->buf_count = len;
-	memset(nandc->data_buffer, 0xff, nandc->buf_count);
-
-	config_nand_single_cw_page_read(chip, false, 0);
-
-	read_data_dma(nandc, FLASH_BUF_ACC, nandc->data_buffer,
-		      nandc->buf_count, 0);
-
-	/* restore CMD1 and VLD regs */
-	if (!nandc->props->qpic_v2) {
-		write_reg_dma(nandc, NAND_DEV_CMD1_RESTORE, 1, 0);
-		write_reg_dma(nandc, NAND_DEV_CMD_VLD_RESTORE, 1, NAND_BAM_NEXT_SGL);
-	}
-
-	ret = submit_descs(nandc);
-	if (ret) {
-		dev_err(nandc->dev, "failure in submitting param page descriptor\n");
-		goto err_out;
-	}
-
-	ret = qcom_wait_rdy_poll(chip, q_op.rdy_timeout_ms);
-	if (ret)
-		goto err_out;
-
-	memcpy(instr->ctx.data.buf.in, nandc->data_buffer, len);
-
-err_out:
-	return ret;
-}
-
-static const struct nand_op_parser qcom_op_parser = NAND_OP_PARSER(
-		NAND_OP_PARSER_PATTERN(
-			qcom_read_id_type_exec,
-			NAND_OP_PARSER_PAT_CMD_ELEM(false),
-			NAND_OP_PARSER_PAT_ADDR_ELEM(false, MAX_ADDRESS_CYCLE),
-			NAND_OP_PARSER_PAT_DATA_IN_ELEM(false, 8)),
-		NAND_OP_PARSER_PATTERN(
-			qcom_read_status_exec,
-			NAND_OP_PARSER_PAT_CMD_ELEM(false),
-			NAND_OP_PARSER_PAT_DATA_IN_ELEM(false, 1)),
-		NAND_OP_PARSER_PATTERN(
-			qcom_param_page_type_exec,
-			NAND_OP_PARSER_PAT_CMD_ELEM(false),
-			NAND_OP_PARSER_PAT_ADDR_ELEM(false, MAX_ADDRESS_CYCLE),
-			NAND_OP_PARSER_PAT_WAITRDY_ELEM(true),
-			NAND_OP_PARSER_PAT_DATA_IN_ELEM(false, 512)),
-		NAND_OP_PARSER_PATTERN(
-			qcom_misc_cmd_type_exec,
-			NAND_OP_PARSER_PAT_CMD_ELEM(false),
-			NAND_OP_PARSER_PAT_ADDR_ELEM(true, MAX_ADDRESS_CYCLE),
-			NAND_OP_PARSER_PAT_CMD_ELEM(true),
-			NAND_OP_PARSER_PAT_WAITRDY_ELEM(false)),
-		);
-
-static int qcom_check_op(struct nand_chip *chip,
-			 const struct nand_operation *op)
-{
-	const struct nand_op_instr *instr;
-	int op_id;
-
-	for (op_id = 0; op_id < op->ninstrs; op_id++) {
-		instr = &op->instrs[op_id];
-
-		switch (instr->type) {
-		case NAND_OP_CMD_INSTR:
-			if (instr->ctx.cmd.opcode != NAND_CMD_RESET  &&
-			    instr->ctx.cmd.opcode != NAND_CMD_READID &&
-			    instr->ctx.cmd.opcode != NAND_CMD_PARAM  &&
-			    instr->ctx.cmd.opcode != NAND_CMD_ERASE1 &&
-			    instr->ctx.cmd.opcode != NAND_CMD_ERASE2 &&
-			    instr->ctx.cmd.opcode != NAND_CMD_STATUS &&
-			    instr->ctx.cmd.opcode != NAND_CMD_PAGEPROG &&
-			    instr->ctx.cmd.opcode != NAND_CMD_READ0 &&
-			    instr->ctx.cmd.opcode != NAND_CMD_READSTART)
-				return -EOPNOTSUPP;
-			break;
-		default:
-			break;
-		}
-	}
-
-	return 0;
-}
-
-static int qcom_nand_exec_op(struct nand_chip *chip,
-			     const struct nand_operation *op, bool check_only)
-{
-	if (check_only)
-		return qcom_check_op(chip, op);
-
-	return nand_op_parser_exec_op(chip, &qcom_op_parser, op, check_only);
-}
-
 static const struct nand_controller_ops qcom_nandc_ops = {
 	.attach_chip = qcom_nand_attach_chip,
-	.exec_op = qcom_nand_exec_op,
 };
 
 static void qcom_nandc_unalloc(struct qcom_nand_controller *nandc)
@@ -3032,6 +3147,11 @@
 
 		if (nandc->cmd_chan)
 			dma_release_channel(nandc->cmd_chan);
+		if (nandc->props->qpic_v2) {
+			if (nandc->sts_chan)
+				dma_release_channel(nandc->sts_chan);
+		}
+
 	} else {
 		if (nandc->chan)
 			dma_release_channel(nandc->chan);
@@ -3056,17 +3176,19 @@
 	 */
 	nandc->buf_size = 532;
 
-	nandc->data_buffer = devm_kzalloc(nandc->dev, nandc->buf_size, GFP_KERNEL);
+	nandc->data_buffer = devm_kzalloc(nandc->dev, nandc->buf_size,
+					GFP_KERNEL);
 	if (!nandc->data_buffer)
 		return -ENOMEM;
 
-	nandc->regs = devm_kzalloc(nandc->dev, sizeof(*nandc->regs), GFP_KERNEL);
+	nandc->regs = devm_kzalloc(nandc->dev, sizeof(*nandc->regs),
+					GFP_KERNEL);
 	if (!nandc->regs)
 		return -ENOMEM;
 
-	nandc->reg_read_buf = devm_kcalloc(nandc->dev, MAX_REG_RD,
-					   sizeof(*nandc->reg_read_buf),
-					   GFP_KERNEL);
+	nandc->reg_read_buf = devm_kcalloc(nandc->dev,
+				MAX_REG_RD, sizeof(*nandc->reg_read_buf),
+				GFP_KERNEL);
 	if (!nandc->reg_read_buf)
 		return -ENOMEM;
 
@@ -3108,10 +3230,18 @@
 			goto unalloc;
 		}
 
+		if (nandc->props->qpic_v2) {
+			nandc->sts_chan = dma_request_slave_channel(nandc->dev, "sts");
+			if (!nandc->sts_chan) {
+				dev_err(nandc->dev, "failed to request sts channel\n");
+				return -ENODEV;
+			}
+		}
+
 		/*
 		 * Initially allocate BAM transaction to read ONFI param page.
 		 * After detecting all the devices, this BAM transaction will
-		 * be freed and the next BAM transaction will be allocated with
+		 * be freed and the next BAM tranasction will be allocated with
 		 * maximum codeword size
 		 */
 		nandc->max_cwperpage = 1;
@@ -3151,7 +3281,7 @@
 	u32 nand_ctrl;
 
 	/* kill onenand */
-	if (!nandc->props->is_qpic)
+	if (!nandc->props->is_qpic && !nandc->props->qpic_v2)
 		nandc_write(nandc, SFLASHC_BURST_CFG, 0);
 
 	if (!nandc->props->qpic_v2)
@@ -3184,6 +3314,584 @@
 	return 0;
 }
 
+static void qspi_write_reg_bam(struct nand_chip *chip,
+		unsigned int val, unsigned int reg)
+{
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	int ret;
+	clear_bam_transaction(nandc);
+	nandc_set_reg(chip, reg, val);
+	write_reg_dma(nandc, reg, 1, NAND_BAM_NEXT_SGL);
+
+	ret = submit_descs(nandc);
+	if (ret)
+		dev_err(nandc->dev, "Error in submitting descriptor to write reg %x\n", reg);
+	free_descs(nandc);
+}
+
+static void qspi_nand_init(struct nand_chip *chip)
+{
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	u32 spi_cfg_val = 0x0;
+	u32 reg = 0x0;
+
+	spi_cfg_val |= (LOAD_CLK_CNTR_INIT_EN | (CLK_CNTR_INIT_VAL_VEC << 16)
+			| (FEA_STATUS_DEV_ADDR << 8) | SPI_CFG);
+
+	qspi_write_reg_bam(chip, 0x0, NAND_FLASH_SPI_CFG);
+	qspi_write_reg_bam(chip, spi_cfg_val, NAND_FLASH_SPI_CFG);
+	spi_cfg_val &= ~LOAD_CLK_CNTR_INIT_EN;
+	qspi_write_reg_bam(chip, spi_cfg_val, NAND_FLASH_SPI_CFG);
+
+	reg = dev_cmd_reg_addr(nandc, NAND_DEV_CMD0);
+	nandc_write(nandc, reg, CMD0_VAL);
+	nandc_write(nandc, reg + 4, CMD1_VAL);
+	nandc_write(nandc, reg + 8, CMD2_VAL);
+	nandc_write(nandc, reg + 12, CMD_VLD_VAL);
+	nandc_write(nandc, reg + 16, CMD7_VAL);
+	reg = dev_cmd_reg_addr(nandc, NAND_DEV_CMD3);
+	nandc_write(nandc, reg, CMD3_VAL);
+
+	qspi_write_reg_bam(chip, SPI_NUM_ADDR, NAND_SPI_NUM_ADDR_CYCLES);
+	qspi_write_reg_bam(chip, WAIT_CNT, NAND_SPI_BUSY_CHECK_WAIT_CNT);
+}
+
+static void qspi_set_phase(struct qcom_nand_controller *nandc,
+		struct qcom_nand_host *host, int phase)
+{
+	struct nand_chip *chip = &host->chip;
+	u32 qspi_cfg_val = 0x0;
+	int reg = dev_cmd_reg_addr(nandc, NAND_FLASH_SPI_CFG);
+
+	qspi_cfg_val = nandc_read(nandc, reg);
+	qspi_cfg_val |= LOAD_CLK_CNTR_INIT_EN;
+
+	qspi_write_reg_bam(chip, qspi_cfg_val, NAND_FLASH_SPI_CFG);
+	qspi_cfg_val &= 0xf000ffff;
+
+	/* Write phase value for all the lines */
+	qspi_cfg_val |= ((phase << 16) | (phase << 19) | (phase << 22)
+			| (phase << 25));
+	qspi_write_reg_bam(chip, qspi_cfg_val, NAND_FLASH_SPI_CFG);
+
+	/* Clear LOAD_CLK_CNTR_INIT_EN bit to load phase value */
+	qspi_cfg_val &= ~LOAD_CLK_CNTR_INIT_EN;
+	qspi_write_reg_bam(chip, qspi_cfg_val, NAND_FLASH_SPI_CFG);
+}
+
+static int qspi_get_appropriate_phase(struct qcom_nand_controller *nandc, u8 *phase_table,
+		int phase_count)
+{
+	int i, cnt = 0, phase = 0x0;
+	u8 phase_ranges[TOTAL_NUM_PHASE] = {'\0'};
+
+	if ( phase_count >= 3) {
+		for (i = 0; i < phase_count -2; i++) {
+			if ((phase_table[i] + 1 == phase_table[i + 1]) &&
+			(phase_table[i + 1] + 1 == phase_table[i + 2]))
+				phase_ranges[cnt++] = phase_table[i + 1];
+		}
+	}
+
+	/* Filter out middle phase */
+	if (cnt == 1)
+		phase = phase_table[1];
+	if (cnt > 1 && cnt <= TOTAL_NUM_PHASE) {
+		if (!(cnt & 1))
+			phase = phase_ranges[cnt/2 - 1];
+		else
+			phase = phase_ranges[cnt/2];
+	}
+
+	return phase;
+}
+
+static int qpic_serial_check_status(__le32 *status)
+{
+	u32 flash  = le32_to_cpu(*(__le32 *)status);
+
+	if (flash & FLASH_ERROR) {
+		if (flash & FS_MPU_ERR)
+			return -EPERM;
+		if (flash & FS_TIMEOUT_ERR)
+			return -ETIMEDOUT;
+		if (flash & FS_OP_ERR)
+			return -EIO;
+	}
+	return 0;
+}
+
+static void qcom_check_quad_mode(struct mtd_info *mtd, struct qcom_nand_host *host)
+{
+	int i, ret;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	unsigned int command = NAND_CMD_READID_SERIAL;
+	u8 id_data[3];
+	u32 cmd3_val;
+
+	pre_command(host, command);
+
+	/* get the device id from device */
+	nandc->buf_count = 4;
+	read_id(host, 0x00);
+
+	ret = submit_descs(nandc);
+	if (ret)
+		dev_err(nandc->dev,
+				"failure submitting descs for command %d\n",
+				command);
+	free_descs(nandc);
+
+	post_command(host, command);
+
+	/* Read Id bytes */
+	for (i = 0; i < 3; i++)
+		id_data[i] = chip->legacy.read_byte(chip);
+	if (id_data[0] == SPI_FLASH_MICRON_ID) {
+		cmd3_val = CMD3_VAL & CMD3_MASK;
+		host->check_qe_bit = false;
+		nandc_write(nandc, dev_cmd_reg_addr(nandc, NAND_DEV_CMD3), cmd3_val);
+	} else if (id_data[0] == SPI_FLASH_GIGA_ID &&
+			id_data[1] == SPI_FLASH_ESMT_DEVICE_ID) {
+	       host->check_qe_bit = false;
+	} else if (id_data[0] == SPI_FLASH_WINBOND_ID &&
+			id_data[1] == SPI_WINBOND_DEVICE_1) {
+	       host->check_qe_bit = false;
+	} else
+		host->check_qe_bit = true;
+}
+
+static int qcom_serial_get_feature(struct qcom_nand_controller *nandc,
+		struct qcom_nand_host *host, u32 faddr)
+{
+	struct nand_chip *chip = &host->chip;
+	u32 cmd_val = 0x0;
+	u32 command = NAND_CMD_GET_FEATURE_SERIAL;
+	int ret;
+
+	/* Clear the BAM transaction index */
+	clear_bam_transaction(nandc);
+
+	cmd_val = (SPI_TRANSFER_MODE_x1 | SPI_WP | SPI_HOLD |
+			ACC_FEATURE);
+
+	pre_command(host, command);
+
+	nandc_set_reg(chip, NAND_FLASH_CMD, cmd_val);
+	nandc_set_reg(chip, NAND_ADDR0, faddr);
+	nandc_set_reg(chip, NAND_ADDR1, 0);
+
+	/* Clear the feature register value to get correct feature value */
+	nandc_set_reg(chip, NAND_FLASH_FEATURES, 0);
+
+	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
+
+	write_reg_dma(nandc, NAND_FLASH_CMD, 3, NAND_BAM_NEXT_SGL);
+
+	write_reg_dma(nandc, NAND_FLASH_FEATURES, 1, NAND_BAM_NEXT_SGL);
+
+	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+
+	read_reg_dma(nandc, NAND_FLASH_FEATURES, 1, NAND_BAM_NEXT_SGL);
+	/* submit the descriptor to bam for execution*/
+	ret = submit_descs(nandc);
+	free_descs(nandc);
+	if (ret) {
+		dev_err(nandc->dev, "Error in submitting descriptor for command:%d\n",
+				command);
+		return ret;
+	}
+
+	nandc_read_buffer_sync(nandc, true);
+
+	/* read_reg_dma will read data in to nandc->reg_read_buf
+	 * so after issueing command in read_reg_dma function read reg_read_buf
+	 * buffer
+	 */
+	ret = le32_to_cpu(*(__le32 *)nandc->reg_read_buf);
+
+	return ret;
+}
+
+static int qcom_serial_set_feature(struct qcom_nand_controller *nandc,
+		struct qcom_nand_host *host, u32 faddr, u32 fval)
+{
+	struct nand_chip *chip = &host->chip;
+	int ret;
+	u32 command = NAND_CMD_SET_FEATURE_SERIAL;
+	u32 cmd_val = (SPI_TRANSFER_MODE_x1 | SPI_WP | SPI_HOLD |
+			ACC_FEATURE | QPIC_SET_FEATURE);
+
+	/* Clear the BAM transaction index */
+	clear_bam_transaction(nandc);
+
+	pre_command(host, command);
+
+	nandc_set_reg(chip, NAND_FLASH_CMD, cmd_val);
+	nandc_set_reg(chip, NAND_ADDR0, faddr);
+	nandc_set_reg(chip, NAND_ADDR1, 0);
+	nandc_set_reg(chip, NAND_FLASH_FEATURES, fval);
+
+	nandc_set_reg(chip, NAND_EXEC_CMD, 1);
+
+	write_reg_dma(nandc, NAND_FLASH_CMD, 3, NAND_BAM_NEXT_SGL);
+
+	write_reg_dma(nandc, NAND_FLASH_FEATURES, 1, NAND_BAM_NEXT_SGL);
+
+	write_reg_dma(nandc, NAND_EXEC_CMD, 1, NAND_BAM_NEXT_SGL);
+
+	read_reg_dma(nandc, NAND_FLASH_STATUS, 1, NAND_BAM_NEXT_SGL);
+
+	/* submit the descriptor to bam for execution*/
+	ret = submit_descs(nandc);
+	free_descs(nandc);
+	if (ret) {
+		dev_err(nandc->dev, "Error in submitting descriptor for command:%d\n",
+				command);
+		return ret;
+	}
+
+	/* read_reg_dma will read data in to nandc->reg_read_buf
+	 * so after issueing command in read_reg_dma function read reg_read_buf
+	 * buffer
+	 */
+	nandc_read_buffer_sync(nandc, true);
+
+	ret = qpic_serial_check_status(nandc->reg_read_buf);
+	if (ret) {
+		dev_err(nandc->dev, "Error in executing command:%d\n",command);
+		return ret;
+	}
+	return ret;
+}
+
+
+static bool config_buf_bit(struct mtd_info *mtd, struct qcom_nand_host *host, u8 *pos)
+{
+	int i, ret;
+	struct nand_chip *chip = mtd_to_nand(mtd);
+	struct qcom_nand_controller *nandc = get_qcom_nand_controller(chip);
+	unsigned int command = NAND_CMD_READID_SERIAL;
+	u8 id_data[3];
+
+	pre_command(host, command);
+
+	/* get the device id from device */
+	nandc->buf_count = 4;
+	read_id(host, 0x00);
+
+	ret = submit_descs(nandc);
+	if (ret)
+		dev_err(nandc->dev, "failure submitting descs for command %d\n",
+				command);
+	free_descs(nandc);
+
+	post_command(host, command);
+
+	/* Read Id bytes */
+	for (i = 0; i < 2; i++)
+		id_data[i] = chip->legacy.read_byte(chip);
+/* Add device ID here if SPI Nand supports BUF_BIT to configure */
+	switch (id_data[0]) {
+	case SPI_FLASH_WINBOND_ID:
+		*pos = 3;
+		return true;
+	default:
+		return false;
+	}
+}
+
+static int qspi_nand_device_config(struct qcom_nand_controller *nandc,
+				   struct qcom_nand_host *host, struct mtd_info *mtd)
+{
+	int status = 0;
+	u8 buf_bit_pos = 0;
+	nandc->buf_count = 4;
+	memset(nandc->reg_read_buf, 0x0, nandc->buf_count);
+	/* Configure BUF bit for SPI Nand device
+	 * Read the id and compare for device id
+	 */
+	if (config_buf_bit(mtd, host, &buf_bit_pos)) {
+		status = qcom_serial_get_feature(nandc, host, SPI_FLASH_FEATURE_REG);
+		if (status < 0) {
+			dev_err(nandc->dev,"Error in getting feature Continous buff");
+			return status;
+		}
+
+		if (!((status >> 8) & SPI_NAND_BUF_BIT(buf_bit_pos))) {
+			dev_dbg(nandc->dev, "Continous buffer mode not enabled on power on\n");
+			dev_dbg(nandc->dev, "Issuing set feature command enbale it\n");
+			status = qcom_serial_set_feature(nandc, host, SPI_FLASH_FEATURE_REG,
+					SPI_NAND_BUF_BIT(buf_bit_pos) | (status >> 8));
+			if (status < 0) {
+				dev_err(nandc->dev,"Error in setting feature Quad mode.");
+				return status;
+			}
+		} else {
+			dev_dbg(nandc->dev, "Continous buffer mode enabled on power on\n");
+		}
+	}
+
+	qcom_check_quad_mode(mtd, host);
+
+	if (!host->check_qe_bit) {
+		host->quad_mode = true;
+		return 0;
+	}
+
+	if (nandc->props->quad_mode) {
+		/* Check if device supports x4 Mode and enable it if not enabled*/
+		status = qcom_serial_get_feature(nandc, host,
+							SPI_FLASH_FEATURE_REG);
+		if (status < 0) {
+			dev_err(nandc->dev, "Error in getting feature x4 mode\n");
+			return status;
+		}
+
+		if (!((status >> 8) & SPI_FLASH_QUAD_MODE)) {
+			/* If x4 mode bit not enabled issue set feature command
+			 * to enable quad mode bit of flash device.
+			 */
+			status = qcom_serial_set_feature(nandc, host,
+							SPI_FLASH_FEATURE_REG,
+							SPI_FLASH_QUAD_MODE);
+			if (status < 0) {
+				dev_err(nandc->dev, "Error in setting feature x4 mode\n");
+				return status;
+			}
+			/* again issue the get feature command to check if quad
+			 * mode is enabled or not
+			 */
+			status = qcom_serial_get_feature(nandc, host,
+							SPI_FLASH_FEATURE_REG);
+			if (status < 0) {
+				dev_err(nandc->dev, "Error in getting feature x4 mode\n");
+				return status;
+			}
+
+			if ((status >> 8) & SPI_FLASH_QUAD_MODE) {
+				host->quad_mode = true;
+				dev_info(nandc->dev, "x4 mode enabled successfully\n");
+			} else {
+				host->quad_mode = false;
+				dev_err(nandc->dev, "x4 mode not enabled, using x1 mode\n");
+				return 0;
+			}
+		} else {
+			dev_info(nandc->dev, "x4 mode enabled already remotely\n");
+			host->quad_mode = true;
+		}
+	}
+	return 0;
+}
+
+static int qspi_execute_training(struct qcom_nand_controller *nandc,
+		struct qcom_nand_host *host, struct mtd_info *mtd)
+{
+	u32 pages_per_block = 0, page = 0;
+	int ret = 0, bb_cnt = 0, i, phase_failed = 0;
+	int phase_cnt, phase;
+	u32 training_offset = 0;
+	u8 *training_data = NULL, trained_phase[TOTAL_NUM_PHASE] = {'\0'};
+	struct nand_chip *chip = &host->chip;
+	int reg;
+
+	u32 max_iomacro_clk = 0;
+	struct device_node *np = nandc->dev->of_node;
+	int sz;
+	u32 *arr = NULL;
+	u32 len = 0;
+
+	/* Set feedback clk enable bit to do auto adjustment of phase
+	 * at lower frequency
+	 */
+	reg = dev_cmd_reg_addr(nandc, NAND_QSPI_MSTR_CONFIG);
+	qspi_write_reg_bam(chip, (nandc_read(nandc,
+			reg) | FEEDBACK_CLK_EN),
+			NAND_QSPI_MSTR_CONFIG);
+
+	/* Read the training offset patched from u-boot */
+	if (of_property_read_u32(np, "qcom,training_offset",
+				&training_offset)) {
+		dev_err(nandc->dev, "Serial training partition not found");
+		ret = -EINVAL;
+		goto trng_err;
+	}
+
+	pages_per_block = 1 << (chip->phys_erase_shift - chip->page_shift);
+	page = (training_offset >> chip->page_shift) & chip->pagemask;
+
+	/* check for bad block in allocated training blocks
+	 * The training blocks should be continuous good block or
+	 * continuous bad block, it should be not like good,bad,good etc.
+	 * avoid to use this type of block for serial training
+	 */
+	while(qcom_nandc_block_bad(chip, training_offset) && bb_cnt < MAX_TRAINING_BLK) {
+		training_offset += mtd->erasesize;
+		page += pages_per_block;
+		bb_cnt++;
+	}
+
+	if (bb_cnt == MAX_TRAINING_BLK) {
+		dev_dbg(nandc->dev, "All training blocks are bad, skipping serial training");
+		dev_dbg(nandc->dev, "Operatig at lower frequency");
+		ret = -EINVAL;
+		goto trng_err;
+	}
+
+	qcom_nandc_command(chip, NAND_CMD_ERASE1, 0, page);
+
+	/* Allocate memory to hold one NAND page */
+	training_data = kzalloc(mtd->writesize, GFP_KERNEL);
+	if (!training_data) {
+		dev_err(nandc->dev, "Error in allocating memory");
+		ret = -ENOMEM;
+		goto trng_err;
+	}
+	memset(training_data, '\0', mtd->writesize);
+
+	for (i = 0; i < mtd->writesize; i += sizeof(qspi_training_block_64))
+		memcpy(training_data + i, qspi_training_block_64,
+			sizeof(qspi_training_block_64));
+
+	/* Write qspi training data to flash */
+	ret = qcom_nandc_write_page(chip, training_data, 0, page);
+	if (ret) {
+		dev_err(nandc->dev, "Error in writing training data");
+		ret = -EINVAL;
+		goto mem_err;
+	}
+
+	/* Read qspi training data @ low freq */
+	memset(training_data, 0xff, mtd->writesize);
+	ret = qcom_nandc_read_page(chip, training_data, 0, page);
+	if (ret < 0) {
+		dev_err(nandc->dev, "Error in reading training data @ low freq");
+		ret = -EINVAL;
+		goto mem_err;
+	}
+
+	/* compare read training data with known pattern */
+	for (i = 0; i <  mtd->writesize; i += sizeof(qspi_training_block_64)) {
+		if (memcmp(training_data + i, qspi_training_block_64,
+				sizeof(qspi_training_block_64))) {
+			dev_err(nandc->dev, "Training data mismatch @ low freq");
+			ret = -EINVAL;
+			goto mem_err;
+		}
+	}
+
+	/* clear feedback clock bit and start training here */
+	qspi_write_reg_bam(chip, (nandc_read(nandc,
+			reg) & ~FEEDBACK_CLK_EN),
+			NAND_QSPI_MSTR_CONFIG);
+
+	/* Get max io macro clock from device tree, value should be
+	 * 200 MHz, 380 MHz, 400 MHz etc.
+	 * */
+	if (of_property_read_u32(np, "qcom,io_macro_max_clk",
+				&max_iomacro_clk)) {
+		dev_err(nandc->dev, "Error in reading max io macro clock from dts");
+		goto mem_err;
+	}
+
+	/* Read all supported io_macro clock frequency from dts */
+	if (!of_get_property(np, "qcom,io_macro_clk_rates", &len)) {
+		dev_err(nandc->dev, "Error in reading length of io_macro_clock\n");
+		goto mem_err;
+	}
+
+	sz = (len / sizeof(*arr));
+
+	arr = kzalloc(sz * sizeof(*arr), GFP_KERNEL);
+	if (!arr) {
+		dev_err(nandc->dev, "failed allocating memory for qcom,io_macro_clk_rates\n");
+		goto mem_err;
+	}
+
+	ret = of_property_read_u32_array(np, "qcom,io_macro_clk_rates", arr, sz);
+	if (ret < 0) {
+		dev_err(nandc->dev, "failed reading array qcom,io_macro_clk_rates %d\n", ret);
+		goto mem_err;
+	}
+
+	sz -= 1;
+
+iomacro_set_clk:
+	ret =  clk_set_rate(nandc->iomacro_clk, max_iomacro_clk);
+	if (ret) {
+		dev_err(nandc->dev,"Setting clk rate to %d MHz failed", max_iomacro_clk);
+		goto mem_err;
+	}
+
+	phase = 1;
+	phase_cnt = 0;
+
+	do {
+		qspi_set_phase(nandc, host, phase);
+
+		/* Prepare clean buffer to read */
+		memset(training_data, 0xff, mtd->writesize);
+		ret = qcom_nandc_read_page(chip, training_data, 0, page);
+		if (ret < 0) {
+			dev_err(nandc->dev, "Error in reading training page at %d MHz",
+					max_iomacro_clk);
+			/* Fall back to next lower clock */
+			if (sz < 0)
+				goto default_freq;
+			max_iomacro_clk = arr[--sz];
+			goto iomacro_set_clk;
+		}
+		/* compare read training data with known pattern */
+		for (i = 0; i <  mtd->writesize; i += sizeof(qspi_training_block_64)) {
+			if (memcmp(training_data + i, qspi_training_block_64,
+					sizeof(qspi_training_block_64))) {
+				phase_failed++;
+				break;
+			}
+		}
+
+		if (i == mtd->writesize)
+			trained_phase[phase_cnt++] = phase;
+
+	} while (phase++ < TOTAL_NUM_PHASE);
+
+	if (phase_cnt) {
+		phase = qspi_get_appropriate_phase(nandc, trained_phase, phase_cnt);
+		if (phase == 0) {
+			dev_err(nandc->dev, "No continous three phase found at %d MHz",
+					max_iomacro_clk);
+			if (sz < 0)
+				goto default_freq;
+			max_iomacro_clk = arr[--sz];
+			goto iomacro_set_clk;
+		}
+		qspi_set_phase(nandc, host, phase);
+	} else {
+default_freq:
+		dev_err(nandc->dev,"Serial training failed");
+		dev_err(nandc->dev, "Running @ low freq 50MHz");
+		/* Run @ lower frequency 50Mhz with feedback clk bit enabled  */
+		qspi_write_reg_bam(chip, (nandc_read(nandc,
+			reg) | FEEDBACK_CLK_EN),
+			NAND_QSPI_MSTR_CONFIG);
+		ret =  clk_set_rate(nandc->iomacro_clk, IO_MACRO_50_MHZ);
+		if (ret) {
+			dev_err(nandc->dev,"Setting clk rate to 50000000 MHz failed");
+			goto mem_err;
+		}
+	}
+
+mem_err:
+	kfree(training_data);
+trng_err:
+	if (arr)
+		kfree(arr);
+	return ret;
+}
+
+
 static const char * const probes[] = { "cmdlinepart", "ofpart", "qcomsmem", NULL };
 
 static int qcom_nand_host_parse_boot_partitions(struct qcom_nand_controller *nandc,
@@ -3196,7 +3902,7 @@ static int qcom_nand_host_parse_boot_partitions(struct qcom_nand_controller *nan
 	struct device *dev = nandc->dev;
 	int partitions_count, i, j, ret;
 
-	if (!of_property_present(dn, "qcom,boot-partitions"))
+	if (!of_find_property(dn, "qcom,boot-partitions", NULL))
 		return 0;
 
 	partitions_count = of_property_count_u32_elems(dn, "qcom,boot-partitions");
@@ -3277,6 +3985,14 @@ static int qcom_nand_host_init_and_register(struct qcom_nand_controller *nandc,
 	mtd->owner = THIS_MODULE;
 	mtd->dev.parent = dev;
 
+	chip->legacy.cmdfunc	= qcom_nandc_command;
+	chip->legacy.select_chip	= qcom_nandc_select_chip;
+	chip->legacy.read_byte	= qcom_nandc_read_byte;
+	chip->legacy.read_buf	= qcom_nandc_read_buf;
+	chip->legacy.write_buf	= qcom_nandc_write_buf;
+	chip->legacy.set_features	= nand_get_set_features_notsupp;
+	chip->legacy.get_features	= nand_get_set_features_notsupp;
+
 	/*
 	 * the bad block marker is readable only when we read the last codeword
 	 * of a page with ECC disabled. currently, the nand_base and nand_bbt
@@ -3295,9 +4011,51 @@ static int qcom_nand_host_init_and_register(struct qcom_nand_controller *nandc,
 	/* set up initial status value */
 	host->status = NAND_STATUS_READY | NAND_STATUS_WP;
 
-	ret = nand_scan(chip, 1);
-	if (ret)
+	if (nandc->props->is_serial_nand) {
+		qspi_nand_init(chip);
+		if (nandc->boot_layout)
+			ret = nand_scan_with_ids(chip, 1, qspinand_flash_ids_2k);
+		else
+			ret = nand_scan(chip, 1);
+	} else {
+		ret = nand_scan(chip, 1);
+	}
+	if (ret) {
+		dev_err(nandc->dev, "nand scan returned error\n");
 		return ret;
+	}
+
+	if (nandc->props->qpic_v2 && nandc->props->page_scope) {
+		nandc->sts_buf_size = (mtd->writesize / NANDC_STEP_SIZE) *
+							MAX_STATUS_REG;
+		nandc->status_buf = devm_kzalloc(nandc->dev, nandc->sts_buf_size,
+				GFP_KERNEL);
+		if (!nandc->status_buf)
+			return -ENOMEM;
+	}
+
+	/* QSPI serial training is required if io_macro clk frequency
+	 * is more than 50MHz. This is due to different PNR and PCB delays,
+	 * serial read data can come with different delays to QPIC. So
+	 * Rx clock should be adjusted according to delays so that Rx Data
+	 * can be captured correctly.
+	 */
+	if (nandc->props->is_serial_nand) {
+		ret = qspi_nand_device_config(nandc, host, mtd);
+		if (ret)
+			dev_err(nandc->dev, "qspi_nand device config failed\n");
+		if (nandc->props->is_serial_training) {
+			if (nandc->boot_layout) {
+				dev_info(nandc->dev,
+				"Skip serial training in boot layout\n");
+			} else {
+				ret = qspi_execute_training(nandc, host, mtd);
+				if (ret)
+					dev_err(nandc->dev,
+					"failed to enable serial training\n");
+			}
+		}
+	}
 
 	ret = mtd_device_parse_register(mtd, probes, NULL, NULL, 0);
 	if (ret)
@@ -3368,9 +4126,63 @@ static int qcom_nandc_parse_dt(struct platform_device *pdev)
 	return 0;
 }
 
+static ssize_t boot_layout_show(struct device *dev,
+				struct device_attribute *attr,
+				char *buf)
+{
+	struct qcom_nand_controller *nandc = dev_get_drvdata(dev);
+
+	return snprintf(buf, PAGE_SIZE, "%u\n", nandc->boot_layout);
+}
+
+static ssize_t boot_layout_store(struct device *dev,
+				struct device_attribute *attr,
+				const char *buf, size_t n)
+{
+	struct qcom_nand_controller *nandc = dev_get_drvdata(dev);
+	struct qcom_nand_host *host, *tmp;
+	int ret;
+
+	ret = kstrtobool(buf, &nandc->boot_layout);
+	if (ret) {
+		dev_err(dev, "invalid boot_layout\n");
+		return ret;
+	}
+
+	list_for_each_entry_safe_reverse(host, tmp, &nandc->host_list, node) {
+		struct nand_chip *chip = &host->chip;
+		struct mtd_info *mtd = nand_to_mtd(chip);
+
+		ret = mtd_device_unregister(mtd);
+		if (ret) {
+			dev_err(dev, "device unregister failed\n");
+			return ret;
+		}
+		memset(mtd, 0, sizeof(struct mtd_info));
+		list_del(&host->node);
+		devm_kfree(nandc->dev, host);
+	}
+
+	if (nandc->props->qpic_v2 && nandc->props->page_scope) {
+		devm_kfree(nandc->dev, nandc->status_buf);
+	}
+
+	ret = qcom_probe_nand_devices(nandc);
+	if (ret) {
+		dev_err(dev, "nand device probe failed\n");
+		return ret;
+	}
+
+	return n;
+}
+
+static const DEVICE_ATTR(boot_layout, 0644, boot_layout_show,
+			boot_layout_store);
+
 static int qcom_nandc_probe(struct platform_device *pdev)
 {
 	struct qcom_nand_controller *nandc;
+	struct qcom_nand_host *host;
 	const void *dev_data;
 	struct device *dev = &pdev->dev;
 	struct resource *res;
@@ -3399,11 +4211,22 @@ static int qcom_nandc_probe(struct platform_device *pdev)
 	if (IS_ERR(nandc->aon_clk))
 		return PTR_ERR(nandc->aon_clk);
 
+	if (nandc->props->is_serial_nand) {
+		nandc->iomacro_clk = devm_clk_get(dev, "io_macro");
+		if (IS_ERR(nandc->iomacro_clk))
+			return PTR_ERR(nandc->iomacro_clk);
+
+		ret =  clk_set_rate(nandc->iomacro_clk, 200000000);
+		if (ret)
+			return ret;
+	}
+
 	ret = qcom_nandc_parse_dt(pdev);
 	if (ret)
 		return ret;
 
-	nandc->base = devm_platform_get_and_ioremap_resource(pdev, 0, &res);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	nandc->base = devm_ioremap_resource(dev, res);
 	if (IS_ERR(nandc->base))
 		return PTR_ERR(nandc->base);
 
@@ -3422,6 +4245,12 @@ static int qcom_nandc_probe(struct platform_device *pdev)
 	if (ret)
 		goto err_aon_clk;
 
+	if (nandc->props->is_serial_nand) {
+		ret = clk_prepare_enable(nandc->iomacro_clk);
+		if (ret)
+			goto err_setup;
+	}
+
 	ret = qcom_nandc_alloc(nandc);
 	if (ret)
 		goto err_nandc_alloc;
@@ -3434,6 +4263,20 @@ static int qcom_nandc_probe(struct platform_device *pdev)
 	if (ret)
 		goto err_setup;
 
+	if (nandc->props->is_serial_nand && nandc->props->switch_layout) {
+		list_for_each_entry(host, &nandc->host_list, node) {
+			struct nand_chip *chip = &host->chip;
+			struct mtd_info *mtd = nand_to_mtd(chip);
+
+			if (mtd->writesize == SZ_4K) {
+				ret = sysfs_create_file(&pdev->dev.kobj,
+							&dev_attr_boot_layout.attr);
+				if (ret)
+					goto err_setup;
+			}
+		}
+	}
+
 	return 0;
 
 err_setup:
@@ -3443,12 +4286,12 @@ static int qcom_nandc_probe(struct platform_device *pdev)
 err_aon_clk:
 	clk_disable_unprepare(nandc->core_clk);
 err_core_clk:
-	dma_unmap_resource(dev, nandc->base_dma, resource_size(res),
+	dma_unmap_resource(dev, res->start, resource_size(res),
 			   DMA_BIDIRECTIONAL, 0);
 	return ret;
 }
 
-static void qcom_nandc_remove(struct platform_device *pdev)
+static int qcom_nandc_remove(struct platform_device *pdev)
 {
 	struct qcom_nand_controller *nandc = platform_get_drvdata(pdev);
 	struct resource *res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
@@ -3463,6 +4306,9 @@ static void qcom_nandc_remove(struct platform_device *pdev)
		nand_cleanup(chip);
	}

+	if (nandc->props->switch_layout)
+		sysfs_remove_file(&pdev->dev.kobj, &dev_attr_boot_layout.attr);
+
	qcom_nandc_unalloc(nandc);
 
	clk_disable_unprepare(nandc->aon_clk);
@@ -3470,6 +4316,8 @@ static void qcom_nandc_remove(struct platform_device *pdev)
 
 	dma_unmap_resource(&pdev->dev, nandc->base_dma, resource_size(res),
 			   DMA_BIDIRECTIONAL, 0);
+
+	return 0;
 }
 
 static const struct qcom_nandc_props ipq806x_nandc_props = {
@@ -3501,6 +4349,39 @@ static const struct qcom_nandc_props sdx55_nandc_props = {
 	.dev_cmd_reg_start = 0x7000,
 };
 
+static const struct qcom_nandc_props ipq5332_nandc_props = {
+	.ecc_modes = (ECC_BCH_4BIT | ECC_BCH_8BIT),
+	.is_bam = true,
+	.is_serial_nand = true,
+	.qpic_v2 = true,
+	.is_serial_training = true,
+	.quad_mode = true,
+	.page_scope = true,
+	.dev_cmd_reg_start = 0x7000,
+};
+
+static const struct qcom_nandc_props devsoc_nandc_props = {
+	.ecc_modes = (ECC_BCH_4BIT | ECC_BCH_8BIT),
+	.is_bam = true,
+	.is_serial_nand = true,
+	.qpic_v2 = true,
+	.quad_mode = true,
+	.page_scope = true,
+	.dev_cmd_reg_start = 0x7000,
+};
+
+static const struct qcom_nandc_props ipq9574_nandc_props = {
+	.ecc_modes = (ECC_BCH_4BIT | ECC_BCH_8BIT),
+	.is_bam = true,
+	.is_serial_nand = true,
+	.qpic_v2 = true,
+	.is_serial_training = true,
+	.quad_mode = true,
+	.page_scope = true,
+	.switch_layout = true,
+	.dev_cmd_reg_start = 0x7000,
+};
+
 /*
  * data will hold a struct pointer containing more differences once we support
  * more controller variants
@@ -3523,6 +4399,18 @@ static const struct of_device_id qcom_nandc_of_match[] = {
 		.data = &ipq8074_nandc_props,
 	},
 	{
+		.compatible = "qcom,ipq5332-nand",
+		.data = &ipq5332_nandc_props,
+	},
+	{
+		.compatible = "qcom,devsoc-nand",
+		.data = &devsoc_nandc_props,
+	},
+	{
+		.compatible = "qcom,ipq9574-nand",
+		.data = &ipq9574_nandc_props,
+	},
+	{
 		.compatible = "qcom,sdx55-nand",
 		.data = &sdx55_nandc_props,
 	},
@@ -3536,7 +4424,7 @@ static struct platform_driver qcom_nandc_driver = {
 		.of_match_table = qcom_nandc_of_match,
 	},
 	.probe   = qcom_nandc_probe,
-	.remove_new = qcom_nandc_remove,
+	.remove  = qcom_nandc_remove,
 };
 module_platform_driver(qcom_nandc_driver);
 
-- 
2.34.1

