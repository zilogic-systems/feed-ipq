From 78165511f2ec240587843c3298a77913bfa56d1a Mon Sep 17 00:00:00 2001
From: Tian Yang <tiany@codeaurora.org>
Date: Tue, 30 Apr 2019 18:43:02 +0530
Subject: [PATCH 363/500] net core: Disable page frag allocations for SKB for
 256MB profile

For low memory profiles such as 256MB, using __alloc_page_frag()
for skb allocations can potentially cause pages to be held up
for longer duration without getting freed by the kernel memory
manageer. This can potentially cause out-of-memory situaions.
This patch disabled page frag based SKB allocations for such
low memory profiles.

Change-Id: Ibc674ad8b46211b8394f0bf7db55366d7210bb01
Signed-off-by: Adil irfan <airfan@codeaurora.org>
Signed-off-by: Kiran Kumar C.S.K <kkumarcs@codeaurora.org>
---
 net/Kconfig       | 8 +++++++-
 net/core/skbuff.c | 8 +++++++-
 2 files changed, 14 insertions(+), 2 deletions(-)

diff --git a/net/Kconfig b/net/Kconfig
index e04a9d7d3373..bbe08315e7ff 100644
--- a/net/Kconfig
+++ b/net/Kconfig
@@ -378,7 +378,6 @@ config SKB_RECYCLER
 	  routing workloads. It can reduce skbuff freeing or
 	  reallocation overhead.
 
-
 config SKB_RECYCLER_MULTI_CPU
 	bool "Cross-CPU recycling for CPU-locked workloads"
 	depends on SMP && SKB_RECYCLER
@@ -402,6 +401,13 @@ config SKB_RECYCLE_MAX_PREALLOC_SKBS
 	help
 	 Number of SKBs each of 4K size to be preallocated for recycling
 
+config ALLOC_SKB_PAGE_FRAG_DISABLE
+	bool "Disable page fragment based skbuff payload allocations"
+	depends on !SKB_RECYCLER
+	default n
+	help
+	 Disable page fragment based allocations for skbuff payloads.
+
 menu "Network testing"
 
 config NET_PKTGEN
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 0c8f2558722b..786b5bdd205e 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -763,16 +763,22 @@ struct sk_buff *__netdev_alloc_skb(struct net_device *dev,
 #else
 	struct page_frag_cache *nc;
 	bool pfmemalloc;
+	bool page_frag_alloc_enable = true;
 	void *data;
 
 	len += NET_SKB_PAD;
 
+
+#ifdef CONFIG_ALLOC_SKB_PAGE_FRAG_DISABLE
+	page_frag_alloc_enable = false;
+#endif
 	/* If requested length is either too small or too big,
 	 * we use kmalloc() for skb->head allocation.
 	 */
 	if (len <= SKB_WITH_OVERHEAD(1024) ||
 	    len > SKB_WITH_OVERHEAD(PAGE_SIZE) ||
-	    (gfp_mask & (__GFP_DIRECT_RECLAIM | GFP_DMA))) {
+	    (gfp_mask & (__GFP_DIRECT_RECLAIM | GFP_DMA)) ||
+	    !page_frag_alloc_enable) {
 		skb = __alloc_skb(len, gfp_mask, SKB_ALLOC_RX, NUMA_NO_NODE);
 		if (!skb)
 			goto skb_fail;
-- 
2.34.1

